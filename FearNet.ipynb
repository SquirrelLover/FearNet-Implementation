{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj2K6Qs9s9bn"
      },
      "source": [
        "Implementation of a Fearnet Variation\n",
        "\n",
        "Authors: Brady Gho, Lucy Wu\n",
        "\n",
        "Source: https://arxiv.org/abs/1711.10563\n",
        "\n",
        "Created on July 25, 2024. Last edited July 30, 2024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pxb1oT_wLvLv"
      },
      "source": [
        "# Defining Imports and Meta-parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ir8RTlFR2G9X"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torch.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, TensorDataset\n",
        "import pdb\n",
        "from collections import defaultdict\n",
        "from torchvision.models import resnet50\n",
        "from torchvision.models import ResNet50_Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hR2-6d6qtZY6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd46071b-3b57-478e-9669-4dc53386869e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7c8275fc9470>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Define meta-Parameters\n",
        "Mini_batch = 450\n",
        "Dropout = 0.5\n",
        "Autoencoder_Hidden_Dims = np.array([1024, 512])\n",
        "Classifier_Dims = np.array([2048, 600, 100])\n",
        "Input_Dim = 2048\n",
        "Learning_Rate = 2e-3\n",
        "HC_Epochs = 25\n",
        "mPFC_Epochs = 35\n",
        "BLA_Epochs = 15\n",
        "\n",
        "torch.manual_seed(42) # seed set for reproducibility"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdVa6JvuLHcT"
      },
      "source": [
        "# Loading and Processing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "8xFkEuoHs45K",
        "outputId": "7996f96b-63b2-4d1a-8542-ceef960bde3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169001437/169001437 [00:13<00:00, 12700544.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Train Loader Images:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x400 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Load Dataset (CIFAR-100)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # insert more transformations of data i.e. normalization\n",
        "])\n",
        "\n",
        "train_data = torchvision.datasets.CIFAR100(root='./data', train=True, transform = transform, download = True)\n",
        "test_data = torchvision.datasets.CIFAR100(root='./data', train=False, transform = transform, download = True)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size = Mini_batch, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size = Mini_batch, shuffle=False)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# view a couple of sample images to make sure they are loaded\n",
        "\n",
        "def display_img_examples(loader):\n",
        "  images, labels = next(iter(loader))\n",
        "  images = images.cpu().detach().numpy()\n",
        "  plt.figure(figsize=(16, 4))\n",
        "  for i in range(4):\n",
        "    plt.subplot(1, 4, i+1)\n",
        "    plt.imshow(np.transpose(images[i], (1, 2, 0)))\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Image of class {labels[i].item()}\")\n",
        "  plt.show()\n",
        "\n",
        "print(\"Train Loader Images:\")\n",
        "display_img_examples(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureDataset(Dataset):\n",
        "    def __init__(self, features=torch.zeros((0, 2048), device=device), labels=torch.zeros(0, device=device)):\n",
        "        self.features = features\n",
        "        self.labels = labels.long()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        feature = self.features[idx]\n",
        "        label = self.labels[idx]\n",
        "        return feature, label\n",
        "\n",
        "    def add_features(self, new_features, new_labels):\n",
        "        self.features = torch.cat((self.features, new_features), dim=0)\n",
        "        self.labels = torch.cat((self.labels, new_labels), dim=0)"
      ],
      "metadata": {
        "id": "JYFPnx-iv1X7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r__2Oki62-8a"
      },
      "outputs": [],
      "source": [
        "# pass data through Resnet processing\n",
        "\n",
        "resnet = resnet50(weights=ResNet50_Weights.DEFAULT) # using ResNet default weights\n",
        "resnet = resnet.to(device)\n",
        "resnet.eval()\n",
        "resnet_feature_extractor = nn.Sequential(*list(resnet.children())[:-1]).to(device)\n",
        "# remove all fc layers except the last one\n",
        "\n",
        "def resnet_process(data_loader):\n",
        "  num_images = len(data_loader) * data_loader.batch_size\n",
        "  feature_vectors = torch.zeros((num_images, 2048), device=device) # 2048 comes from output of Resnet processing\n",
        "  labels = torch.zeros(num_images, device=device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i, (images, labels_batch) in enumerate(data_loader):\n",
        "      images = images.to(device)\n",
        "      labels_batch = labels_batch.to(device)\n",
        "      features_batch = resnet_feature_extractor(images).squeeze()\n",
        "      start_index = i * Mini_batch\n",
        "      end_index = start_index + features_batch.shape[0]\n",
        "      feature_vectors[start_index:end_index] = features_batch\n",
        "      labels[start_index:end_index] = labels_batch\n",
        "\n",
        "  return DataLoader(FeatureDataset(feature_vectors, labels)) # num workers and pin_memory are for efficiency\n",
        "\n",
        "train_loader_processed = resnet_process(train_loader)\n",
        "test_loader_processed = resnet_process(test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GPXUTBkygJd"
      },
      "source": [
        "# Evaluate the Performance of Resnet on CIFAR-100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hzMmn2s6yn3z"
      },
      "outputs": [],
      "source": [
        "resnet_test = resnet50(pretrained=True)\n",
        "num_features = resnet_test.fc.in_features\n",
        "resnet_test.fc = nn.Linear(num_features, 100)\n",
        "resnet_test.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIhPefE0zHBV"
      },
      "outputs": [],
      "source": [
        "# loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(resnet_test.parameters(), lr=0.001)\n",
        "\n",
        "# training function\n",
        "def training_step(model, data_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for images, labels in data_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    average_loss = total_loss / len(data_loader)\n",
        "    return average_loss\n",
        "\n",
        "# calculate accuracy\n",
        "def calculate_accuracy(model, data_loader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy\n",
        "\n",
        "# training\n",
        "num_epochs = 30\n",
        "for epoch in range(num_epochs):\n",
        "    avg_loss = training_step(resnet_test, train_loader, criterion, optimizer, device)\n",
        "    accuracy = calculate_accuracy(resnet_test, test_loader, device)\n",
        "    print(f\"Epoch {epoch+1}, Loss: {avg_loss}, Accuracy: {accuracy}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yPzQeiNwYdF"
      },
      "outputs": [],
      "source": [
        "# test accuracy\n",
        "\n",
        "def evaluate_model(model, data_loader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy\n",
        "\n",
        "# Evaluate the model\n",
        "test_accuracy = evaluate_model(resnet_test, test_loader, device)\n",
        "print(f'Test Accuracy of the model on the 10000 test images: {test_accuracy:.2f}%')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfYC56dhLO8u"
      },
      "source": [
        "# Hippocampus Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "BLWq-gNEtX_6"
      },
      "outputs": [],
      "source": [
        "# define HC\n",
        "\n",
        "class HC(nn.Module):\n",
        "  def __init__(self, classifier_dims = Classifier_Dims, learning_rate= Learning_Rate, p_dropout=Dropout):\n",
        "    super(HC, self).__init__()\n",
        "\n",
        "    self.short_term_memory = FeatureDataset()\n",
        "\n",
        "    classifier_layers = []\n",
        "    current_dim = classifier_dims[0]\n",
        "\n",
        "    if len(classifier_dims)!=1:\n",
        "      # Avoid dropping out the first layer of processing and output layer\n",
        "      classifier_layers.append(nn.Linear(current_dim, classifier_dims[0]))\n",
        "      classifier_layers.append(nn.ReLU())\n",
        "\n",
        "      for i in range(1, len(classifier_dims)-1):\n",
        "        hidden_dim = classifier_dims[i]\n",
        "        classifier_layers.append(nn.Linear(current_dim, hidden_dim))\n",
        "        classifier_layers.append(nn.ReLU())\n",
        "        classifier_layers.append(nn.Dropout(p=p_dropout))\n",
        "        current_dim = hidden_dim\n",
        "\n",
        "    classifier_layers.append(nn.Linear(current_dim, classifier_dims[len(classifier_dims)-1]))\n",
        "\n",
        "    self.classifier = nn.Sequential(*classifier_layers)\n",
        "\n",
        "    # Using Adam Optimizer\n",
        "    self.optimizer = optim.Adam(self.parameters(), lr = learning_rate)\n",
        "    self.CrossEntropyLoss = nn.CrossEntropyLoss()\n",
        "\n",
        "  def forward(self, x, is_storing = False):\n",
        "    if (is_storing):\n",
        "      features = x[0].squeeze()\n",
        "      labels = x[1].squeeze()\n",
        "      self.short_term_memory.add_features(features, labels)\n",
        "    class_logits = self.classifier(x)\n",
        "    return class_logits\n",
        "\n",
        "  def clear_memory(self):\n",
        "    memory = self.short_term_memory\n",
        "    self.short_term_memory = FeatureDataset()\n",
        "    return memory\n",
        "\n",
        "  def training_step(self, dataloader):\n",
        "    total_loss = 0\n",
        "\n",
        "    self.train()\n",
        "    optimizer = self.optimizer\n",
        "\n",
        "    for features, targets in dataloader:\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      class_logits = self.forward(features, is_storing=True)\n",
        "      loss = self.CrossEntropyLoss(class_logits, targets)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      total_loss += loss\n",
        "\n",
        "    return (total_loss / (len(dataloader) * dataloader.batch_size))\n",
        "\n",
        "  def calc_accuracy(self, dataloader):\n",
        "    total_correct = 0\n",
        "\n",
        "    self.eval()\n",
        "    with torch.no_grad():\n",
        "      for features, targets in dataloader:\n",
        "        predictions = self.forward(features, is_storing=False)\n",
        "        predictions = torch.argmax(predictions, dim=1)\n",
        "\n",
        "        correct = (predictions == targets).sum().item()\n",
        "        total_correct += correct\n",
        "\n",
        "    return (total_correct / (len(dataloader) * dataloader.batch_size))*100\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "\n",
        "hippocampus = HC()\n",
        "hippocampus.to(device)\n",
        "\n",
        "loss_history = []\n",
        "for epoch in range(50):\n",
        "  loss = hippocampus.training_step(train_loader_processed)\n",
        "  loss_history.append(loss)\n",
        "  accuracy = hippocampus.calc_accuracy(train_loader_processed)\n",
        "  print(f\"Epoch {epoch+1}: Loss is {loss:.4f}, Accuracy is {accuracy:.4f}%\")\n",
        "\n",
        "print(f\"Accuracy is {hippocampus.calc_accuracy(test_loader_processed):.4f}%\")"
      ],
      "metadata": {
        "id": "GKPmSaeDjyHn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "57b29b6e-dcfe-48f3-b516-c6ffd1739ce7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-32-7549d78543a2>\", line 10, in __getitem__\n    feature = self.features[idx]\nRuntimeError: CUDA error: initialization error\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-2256834b0522>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mloss_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhippocampus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader_processed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mloss_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhippocampus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader_processed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-564380f650c9>\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, dataloader)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1344\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1346\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-32-7549d78543a2>\", line 10, in __getitem__\n    feature = self.features[idx]\nRuntimeError: CUDA error: initialization error\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iAOTMobLSnf"
      },
      "source": [
        "# Pre-frontal Cortex  Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "9213wTvFtRdp"
      },
      "outputs": [],
      "source": [
        "# define mPFC (long term)\n",
        "\n",
        "class mPFC(nn.Module):\n",
        "  def __init__(self, input_dim=2048, autoencoder_hidden_dims = np.array([1024, 512]), classifier_dims = np.array([100]), lambda_values=[1e4, 1, 0.1], learning_rate=5e-4):\n",
        "    super(mPFC, self).__init__()\n",
        "    # encoder\n",
        "    encoder_layers = []\n",
        "    current_dim = input_dim\n",
        "    encoder_layers.append(nn.ELU())\n",
        "    for hidden_dim in autoencoder_hidden_dims:\n",
        "      encoder_layers.append(nn.Linear(current_dim, hidden_dim))\n",
        "      encoder_layers.append(nn.ELU())\n",
        "      current_dim = hidden_dim\n",
        "    self.encoder = nn.Sequential(*encoder_layers)\n",
        "\n",
        "    # decoder\n",
        "    decoder_layers = []\n",
        "    hidden_dims_reversed = list(autoencoder_hidden_dims[::-1])\n",
        "    for hidden_dim in hidden_dims_reversed:\n",
        "      decoder_layers.append(nn.Linear(current_dim, hidden_dim))\n",
        "      decoder_layers.append(nn.ELU())\n",
        "      current_dim = hidden_dim\n",
        "    decoder_layers.append(nn.Linear(current_dim, input_dim))\n",
        "    decoder_layers.append(nn.ELU())\n",
        "    self.decoder = nn.Sequential(*decoder_layers)\n",
        "\n",
        "    #classifier\n",
        "    current_dim = autoencoder_hidden_dims[-1]\n",
        "    classifier_layers= []\n",
        "\n",
        "    if len(classifier_dims) != 1:\n",
        "      classifier_layers.append(nn.Linear(current_dim, classifier_dims[0]))\n",
        "      classifier_layers.append(nn.ELU())\n",
        "      current_dim = classifier_dims[0]\n",
        "\n",
        "      for i in range(1, len(classifier_dims)-1):\n",
        "        hidden_dim = classifier_dims[i]\n",
        "        classifier_layers.append(nn.Linear(current_dim, hidden_dim))\n",
        "        classifier_layers.append(nn.ELU())\n",
        "        classifier_layers.append(nn.Dropout(p=Dropout))\n",
        "        current_dim = hidden_dim\n",
        "\n",
        "    classifier_layers.append(nn.Linear(current_dim, classifier_dims[len(classifier_dims)-1]))\n",
        "\n",
        "    self.classifier = nn.Sequential(*classifier_layers)\n",
        "\n",
        "    # lambda\n",
        "    self.lambda_values = torch.tensor(lambda_values if lambda_values else [1.0] * len(autoencoder_hidden_dims), dtype=torch.float32)\n",
        "\n",
        "    # optimizer\n",
        "    self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
        "\n",
        "    #session number\n",
        "    self.class_means = defaultdict(dict)\n",
        "    self.class_covariances = defaultdict(dict)\n",
        "\n",
        "  def encoder_forward(self, x):\n",
        "    encoder_intermediates = [x]\n",
        "    for layer in self.encoder:\n",
        "      x = layer(x)\n",
        "      encoder_intermediates.append(x)\n",
        "    encoded = encoder_intermediates[-1]\n",
        "    return encoded, encoder_intermediates\n",
        "\n",
        "  def decoder_forward(self, x):\n",
        "    decoder_intermediates = [x]\n",
        "    for layer in self.decoder:\n",
        "      x = layer(x)\n",
        "      decoder_intermediates.append(x)\n",
        "    pseudo_img = decoder_intermediates[-1]\n",
        "    return pseudo_img, list(decoder_intermediates[::-1])\n",
        "\n",
        "  def classify(self, x):\n",
        "    class_logits = self.classifier(x)\n",
        "    return class_logits\n",
        "\n",
        "  def compute_loss(self, class_logits, targets, encoder_intermediates, decoder_intermediates):\n",
        "    # classification loss\n",
        "    classification_loss = nn.CrossEntropyLoss()(class_logits, targets)\n",
        "\n",
        "    # reconstruction loss with lambda weighting\n",
        "    reconstruction_loss = 0\n",
        "    for i in range(len(self.lambda_values)):\n",
        "      encoder_hidden = encoder_intermediates[i]\n",
        "      decoder_hidden = decoder_intermediates[i]\n",
        "      diff = encoder_hidden - decoder_hidden\n",
        "      squared_diff = diff.pow(2)\n",
        "      layer_loss = squared_diff.sum()\n",
        "      reconstruction_loss += self.lambda_values[i] * layer_loss\n",
        "\n",
        "    # total loss\n",
        "    total_loss = classification_loss + reconstruction_loss\n",
        "\n",
        "    return classification_loss, reconstruction_loss, total_loss\n",
        "\n",
        "  def training_step(self, data_loader, device):\n",
        "    self.train()\n",
        "\n",
        "    total_classification_loss = 0\n",
        "    total_reconstruction_loss = 0\n",
        "    total_total_loss = 0\n",
        "\n",
        "    for x, targets in data_loader:\n",
        "      x, targets = x.to(device), targets.to(device)\n",
        "\n",
        "      # forward pass\n",
        "      encoded, encoder_intermediates = self.encoder_forward(x)\n",
        "      pseudo_img, decoder_intermediates = self.decoder_forward(encoded)\n",
        "      class_logits = self.classify(encoded)\n",
        "\n",
        "      # compute losses\n",
        "      classification_loss, reconstruction_loss, total_loss = self.compute_loss(\n",
        "        class_logits, targets, encoder_intermediates, decoder_intermediates\n",
        "      )\n",
        "\n",
        "      # zero gradients\n",
        "      self.optimizer.zero_grad()\n",
        "\n",
        "      # backward pass\n",
        "      classification_loss.backward(retain_graph=True)\n",
        "      classifier_grads = {name: param.grad.clone() for name, param in self.classifier.named_parameters()}\n",
        "      reconstruction_loss.backward(retain_graph=True)\n",
        "      decoder_grads = {name: param.grad.clone() for name, param in self.decoder.named_parameters()}\n",
        "      total_loss.backward()\n",
        "      encoder_grads = {name: param.grad.clone() for name, param in self.encoder.named_parameters()}\n",
        "\n",
        "      # optimizer\n",
        "      encoder_optimizer = optim.Adam(self.encoder.parameters(), lr=self.optimizer.defaults['lr'])\n",
        "      encoder_optimizer.step()\n",
        "      classifier_optimizer = optim.Adam(self.classifier.parameters(), lr=self.optimizer.defaults['lr'])\n",
        "      classifier_optimizer.step()\n",
        "      decoder_optimizer = optim.Adam(self.decoder.parameters(), lr=self.optimizer.defaults['lr'])\n",
        "      decoder_optimizer.step()\n",
        "\n",
        "      # update parameters\n",
        "      for name, param in self.classifier.named_parameters():\n",
        "        if param.grad is not None:\n",
        "          param.grad.data = classifier_grads[name].data\n",
        "      for name, param in self.decoder.named_parameters():\n",
        "        if param.grad is not None:\n",
        "          param.grad.data = decoder_grads[name].data\n",
        "      for name, param in self.encoder.named_parameters():\n",
        "        if param.grad is not None:\n",
        "          param.grad.data = encoder_grads[name].data\n",
        "\n",
        "      # add losses to total\n",
        "      total_classification_loss += classification_loss.item()\n",
        "      total_reconstruction_loss += reconstruction_loss.item()\n",
        "      total_total_loss += total_loss.item()\n",
        "\n",
        "    # average loss\n",
        "    average_classification_loss = total_classification_loss / len(data_loader)\n",
        "    average_reconstruction_loss = total_reconstruction_loss / len(data_loader)\n",
        "    average_total_loss = total_total_loss / len(data_loader)\n",
        "\n",
        "    return average_classification_loss, average_reconstruction_loss, average_total_loss\n",
        "\n",
        "  def consolidate_statistics(self):\n",
        "    # compute the average mean vector and covariance matrix for each class\n",
        "    for label in self.class_means:\n",
        "      if self.class_means[label]:\n",
        "        means = torch.stack(self.class_means[label])\n",
        "        covariances = torch.stack(self.class_covariances[label])\n",
        "\n",
        "        # average the mean vectors and covariance matrices\n",
        "        consolidated_mean = means.mean(dim=0)\n",
        "        consolidated_covariance = covariances.mean(dim=0)\n",
        "\n",
        "        # update the consolidated statistics\n",
        "        self.class_means[label] = consolidated_mean\n",
        "        self.class_covariances[label] = consolidated_covariance\n",
        "\n",
        "  def generate_statistics(self, feature_vectors, labels, device):\n",
        "    # current session class statistics\n",
        "    class_features = defaultdict(list)\n",
        "\n",
        "    for feature, label in zip(feature_vectors, labels):\n",
        "      class_features[label.item()].append(feature)\n",
        "\n",
        "    for label, features in class_features.items():\n",
        "      features = torch.stack(features).to(device)\n",
        "      mean_vector = features.mean(dim=0)\n",
        "      centered_features = features - mean_vector\n",
        "      covariance_matrix = torch.mm(centered_features.t(), centered_features) / (features.size(0) - 1)\n",
        "\n",
        "      # append the current session's statistics\n",
        "      self.class_means[label].append(mean_vector)\n",
        "      self.class_covariances[label].append(covariance_matrix)\n",
        "\n",
        "      self.consolidate_statistics()\n",
        "\n",
        "  def pseudoimg_from_statistics(self, num_examples_per_class, device):\n",
        "    self.eval()\n",
        "\n",
        "    pseudo_examples = []\n",
        "    pseudo_labels = []\n",
        "\n",
        "    for label, mean_vector in self.class_means.items():\n",
        "      if isinstance(mean_vector, torch.Tensor):\n",
        "        covariance_matrix = self.class_covariances[label]\n",
        "\n",
        "        # create a multivariate normal distribution\n",
        "        mvn = dist.MultivariateNormal(mean_vector, covariance_matrix)\n",
        "\n",
        "        # generate pseudo-examples\n",
        "        examples = mvn.sample((num_examples_per_class,)).to(device)\n",
        "        labels = torch.full((num_examples_per_class,), label, dtype=torch.long, device=device)\n",
        "\n",
        "        pseudo_examples.append(examples)\n",
        "        pseudo_labels.append(labels)\n",
        "\n",
        "    pseudo_examples = torch.cat(pseudo_examples)\n",
        "    pseudo_labels = torch.cat(pseudo_labels)\n",
        "\n",
        "    return pseudo_examples, pseudo_labels\n",
        "\n",
        "  def calculate_accuracy(self, data_loader, device):\n",
        "    self.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for x, targets in data_loader:\n",
        "        x, targets = x.to(device), targets.to(device)\n",
        "        encoded, _ = self.encoder_forward(x)\n",
        "        class_logits = self.classify(encoded)\n",
        "        _, predicted = torch.max(class_logits.data, 1)\n",
        "        total += targets.size(0)\n",
        "        correct += (predicted == targets).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy\n",
        "\n",
        "mPFC = mPFC()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKg46QH1Lefr"
      },
      "source": [
        "# BLA Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "JGy_SZT9tdgY"
      },
      "outputs": [],
      "source": [
        "# Define BLA\n",
        "\n",
        "class BLA(nn.Module):\n",
        "\n",
        "  def __init__(self, classifier_dims = Classifier_Dims, learning_rate= Learning_Rate, p_dropout=Dropout):\n",
        "    super(BLA, self).__init__()\n",
        "\n",
        "    classifier_layers = []\n",
        "    current_dim = classifier_dims[0]\n",
        "\n",
        "    if len(classifier_dims)!=1:\n",
        "      # Avoid dropping out the first layer of processing and output layer\n",
        "      classifier_layers.append(nn.Linear(current_dim, classifier_dims[0]))\n",
        "      classifier_layers.append(nn.ReLU())\n",
        "\n",
        "      for i in range(1, len(classifier_dims)):\n",
        "        hidden_dim = classifier_dims[i]\n",
        "        classifier_layers.append(nn.Linear(current_dim, hidden_dim))\n",
        "        classifier_layers.append(nn.ReLU())\n",
        "        classifier_layers.append(nn.Dropout(p=p_dropout))\n",
        "        current_dim = hidden_dim\n",
        "\n",
        "    classifier_layers.append(nn.Linear(current_dim, 1))\n",
        "\n",
        "    self.classifier = nn.Sequential(*classifier_layers)\n",
        "\n",
        "    # Using Adam Optimizer\n",
        "    self.optimizer = optim.Adam(self.parameters(), lr = learning_rate)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    class_logits = self.classifier(x)\n",
        "    return class_logits\n",
        "\n",
        "  def training_step(self, dataloader, HC, mPFC):\n",
        "    total_loss = 0\n",
        "\n",
        "    self.train()\n",
        "    HC.eval()\n",
        "    mPFC.eval()\n",
        "    for features, label in dataloader:\n",
        "      HC_logits = []\n",
        "      mPFC_logits = []\n",
        "\n",
        "      with torch.no_grad():\n",
        "        HC_logits = HC.forward(features)\n",
        "        mPFC_logits = mPFC.forward(features)\n",
        "\n",
        "      optimizer = self.optimizer\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      class_prob = self.Softmax(self.forward(features))\n",
        "\n",
        "      HC_prob = nn.Softmax(HC_logits)\n",
        "      mPFC_prob = nn.Softmax(mPFC_logits)\n",
        "\n",
        "      loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "      HC_loss = loss_fn(HC_prob, labels)\n",
        "      mPFC_loss = loss_fn(mPFC_prob, labels)\n",
        "\n",
        "      # Determine if HC or mPFC is more accurate\n",
        "      target_is_HC = HC_loss > mPFC_loss\n",
        "      target_is_HC = target_is_HC.float().view(-1, 1)  # Convert to float and reshape for broadcasting\n",
        "\n",
        "      # Calculate the BLA loss based on whether the prediction aligns with the more accurate model\n",
        "      BLA_target = target_is_HC\n",
        "      BLA_loss = nn.BCELoss()(class_prob, BLA_target)\n",
        "\n",
        "      BLA_loss.backwards()\n",
        "      optimizer.step()\n",
        "\n",
        "      total_loss += BLA_loss\n",
        "\n",
        "    return (total_loss / (len(dataloader) * dataloader.batch_size))\n",
        "\n",
        "Bla = BLA()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_M6temMLhK_"
      },
      "source": [
        "# Dual Memory System Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "7_dX6yZDtixQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "682bc3e5-33e7-4a84-9b89-dd74506249e8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'autoencoder_dims' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-f962db523f7c>\u001b[0m in \u001b[0;36m<cell line: 82>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcombined_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m \u001b[0mDMSM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDMSM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-f962db523f7c>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dim, classifier_dims, learning_rate, p_dropout, lambda_values)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_dropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbla\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBLA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_dropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmpfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmPFC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautoencoder_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHC_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHC_Epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBLA_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBLA_Epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'autoencoder_dims' is not defined"
          ]
        }
      ],
      "source": [
        "# dmsm\n",
        "\n",
        "class DMSM(nn.Module):\n",
        "  def __init__(self, input_dim=Input_Dim, classifier_dims = Classifier_Dims, learning_rate=Learning_Rate, p_dropout=Dropout, lambda_values = [1e4, 1.0, 0.1]):\n",
        "    super(DMSM, self).__init__()\n",
        "    self.hc = HC(classifier_dims, learning_rate, p_dropout)\n",
        "    self.bla = BLA(classifier_dims, learning_rate, p_dropout)\n",
        "    self.mpfc = mPFC(input_dim, autoencoder_dims, classifier_dims, lambda_values, learning_rate)\n",
        "\n",
        "  def training(self, dataloader, HC_epochs = HC_Epochs, BLA_epochs = BLA_Epochs):\n",
        "    mPFC = self.mPFC\n",
        "    HC = self.HC\n",
        "    BLA = self.BLA\n",
        "\n",
        "    HC_loss_history = []\n",
        "    BLA_loss_history = []\n",
        "\n",
        "    # Train HC\n",
        "    for epoch in range(HC_epochs):\n",
        "      HC_loss_history.append(HC.training_step(dataloader))\n",
        "\n",
        "    # Integrate hallucinated images into the dataloader\n",
        "\n",
        "\n",
        "    # Train BLA\n",
        "    for epoch in range(BLA_epochs):\n",
        "      BLA_loss_history.append(BLA.training_step(dataloader))\n",
        "\n",
        "    return HC_loss_history, BLA_loss_history\n",
        "\n",
        "  def sleep(self, mPFC_Epochs = mPFC_Epochs):\n",
        "    mPFC = self.mPFC\n",
        "    HC = self.HC\n",
        "    BLA = self.BLA\n",
        "\n",
        "    mPFC_loss_history = []\n",
        "\n",
        "    short_term_data = HC.clear_memory()\n",
        "\n",
        "    # Integrate hallucinated images into short term memory data\n",
        "    #\n",
        "    #\n",
        "    #\n",
        "    #\n",
        "\n",
        "    for epoch in range(mPFC_Epochs):\n",
        "      mPFC_Epochs.training_step()\n",
        "\n",
        "  def eval(self, dataloader):\n",
        "    mPFC = self.mPFC\n",
        "    HC = self.HC\n",
        "    BLA = self.BLA\n",
        "\n",
        "    HC.eval()\n",
        "    mPFC.eval()\n",
        "    BLA.eval()\n",
        "\n",
        "    all_inputs = []\n",
        "    all_targets = []\n",
        "    for inputs, targets in dataloader:\n",
        "      all_inputs.append(inputs)\n",
        "      all_targets.append(targets)\n",
        "\n",
        "    all_inputs = torch.cat(all_inputs)\n",
        "    all_targets = torch.cat(all_targets)\n",
        "\n",
        "    predictions = BLA.forward(all_inputs.to(device))\n",
        "    predictions_rounded = torch.round(predictions)\n",
        "\n",
        "    HC_mask = (predictions_rounded == 0).squeeze()\n",
        "    mPFC_mask = (predictions_rounded == 1).squeeze()\n",
        "\n",
        "    HC_output = HC.forward(all_inputs[HC_mask].to(device))\n",
        "    mPFC_output = mPFC.forward(all_inputs[mPFC_mask].to(device))\n",
        "\n",
        "    combined_output = torch.zeros_like(predictions).to(device)\n",
        "    combined_output[HC_mask] = HC_output\n",
        "    combined_output[mPFC_mask] = mPFC_output\n",
        "\n",
        "    return combined_output\n",
        "\n",
        "DMSM = DMSM()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKJvA-5lt9N1"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "3GPXUTBkygJd",
        "EKg46QH1Lefr",
        "I_M6temMLhK_"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
