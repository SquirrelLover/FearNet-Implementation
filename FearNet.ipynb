{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SquirrelLover/FearNet-Implementation/blob/main/FearNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj2K6Qs9s9bn"
      },
      "source": [
        "Implementation of a Fearnet Variation\n",
        "\n",
        "Authors: Brady Gho, Lucy Wu\n",
        "\n",
        "Source: https://arxiv.org/abs/1711.10563\n",
        "\n",
        "Created on July 25, 2024. Last edited July 25, 2024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pxb1oT_wLvLv"
      },
      "source": [
        "# Defining Imports and Meta-parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "ir8RTlFR2G9X"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torch.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, TensorDataset\n",
        "import pdb\n",
        "from collections import defaultdict\n",
        "from torchvision.models import resnet50\n",
        "from torchvision.models import ResNet50_Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hR2-6d6qtZY6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d11a02f6-f430-4812-9b6f-f5526d5a679b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f3cddda54f0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Define meta-Parameters\n",
        "Mini_batch = 450\n",
        "Dropout = 0.5\n",
        "VAE_dims = np.array([256])\n",
        "Classifier_Dims = np.array([2048, 600, 100])\n",
        "Input_Dim = 2048\n",
        "Learning_Rate = 2e-3\n",
        "HC_Epochs = 25\n",
        "mPFC_Epochs = 35\n",
        "BLA_Epochs = 15\n",
        "\n",
        "torch.manual_seed(42) # seed set for reproducibility"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdVa6JvuLHcT"
      },
      "source": [
        "# Loading and Processing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "8xFkEuoHs45K",
        "outputId": "def4e19a-cd6c-469a-9ec8-c3625d5a5404"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Train Loader Images:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x400 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Load Dataset (CIFAR-100)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # insert more transformations of data i.e. normalization\n",
        "])\n",
        "\n",
        "train_data = torchvision.datasets.CIFAR100(root='./data', train=True, transform = transform, download = True)\n",
        "test_data = torchvision.datasets.CIFAR100(root='./data', train=False, transform = transform, download = True)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size = Mini_batch, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size = Mini_batch, shuffle=False)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# view a couple of sample images to make sure they are loaded\n",
        "\n",
        "def display_img_examples(loader):\n",
        "  images, labels = next(iter(loader))\n",
        "  images = images.cpu().detach().numpy()\n",
        "  plt.figure(figsize=(16, 4))\n",
        "  for i in range(4):\n",
        "    plt.subplot(1, 4, i+1)\n",
        "    plt.imshow(np.transpose(images[i], (1, 2, 0)))\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Image of class {labels[i].item()}\")\n",
        "  plt.show()\n",
        "\n",
        "print(\"Train Loader Images:\")\n",
        "display_img_examples(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = features\n",
        "        self.labels = labels.long()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        feature = self.features[idx]\n",
        "        label = self.labels[idx]\n",
        "        return feature, label\n",
        "\n",
        "    def add_features(self, new_features, new_labels):\n",
        "        self.features = torch.cat((self.features, new_features), dim=0)\n",
        "        self.labels = torch.cat((self.labels, new_labels), dim=0)"
      ],
      "metadata": {
        "id": "JYFPnx-iv1X7"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "r__2Oki62-8a"
      },
      "outputs": [],
      "source": [
        "# pass data through Resnet processing\n",
        "\n",
        "resnet = resnet50(weights=ResNet50_Weights.DEFAULT) # using ResNet default weights\n",
        "resnet = resnet.to(device)\n",
        "resnet.eval()\n",
        "resnet_feature_extractor = nn.Sequential(*list(resnet.children())[:-1]).to(device)\n",
        "# remove all fc layers except the last one\n",
        "\n",
        "def resnet_process(data_loader):\n",
        "  num_images = len(data_loader) * data_loader.batch_size\n",
        "  feature_vectors = torch.zeros((num_images, 2048), device=device) # 2048 comes from output of Resnet processing\n",
        "  labels = torch.zeros(num_images, device=device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i, (images, labels_batch) in enumerate(data_loader):\n",
        "      images = images.to(device)\n",
        "      labels_batch = labels_batch.to(device)\n",
        "      features_batch = resnet_feature_extractor(images).squeeze()\n",
        "      start_index = i * Mini_batch\n",
        "      end_index = start_index + features_batch.shape[0]\n",
        "      feature_vectors[start_index:end_index] = features_batch\n",
        "      labels[start_index:end_index] = labels_batch\n",
        "\n",
        "  return DataLoader(FeatureDataset(feature_vectors, labels))\n",
        "\n",
        "train_loader_processed = resnet_process(train_loader)\n",
        "test_loader_processed = resnet_process(test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GPXUTBkygJd"
      },
      "source": [
        "# Evaluate the Performance of Resnet on CIFAR-100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hzMmn2s6yn3z"
      },
      "outputs": [],
      "source": [
        "resnet_test = resnet50(pretrained=True)\n",
        "num_features = resnet_test.fc.in_features\n",
        "resnet_test.fc = nn.Linear(num_features, 100)\n",
        "resnet_test.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIhPefE0zHBV"
      },
      "outputs": [],
      "source": [
        "# loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(resnet_test.parameters(), lr=0.001)\n",
        "\n",
        "# training function\n",
        "def training_step(model, data_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for images, labels in data_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    average_loss = total_loss / len(data_loader)\n",
        "    return average_loss\n",
        "\n",
        "# calculate accuracy\n",
        "def calculate_accuracy(model, data_loader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy\n",
        "\n",
        "# training\n",
        "num_epochs = 30\n",
        "for epoch in range(num_epochs):\n",
        "    avg_loss = training_step(resnet_test, train_loader, criterion, optimizer, device)\n",
        "    accuracy = calculate_accuracy(resnet_test, test_loader, device)\n",
        "    print(f\"Epoch {epoch+1}, Loss: {avg_loss}, Accuracy: {accuracy}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yPzQeiNwYdF"
      },
      "outputs": [],
      "source": [
        "# test accuracy\n",
        "\n",
        "def evaluate_model(model, data_loader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy\n",
        "\n",
        "# Evaluate the model\n",
        "test_accuracy = evaluate_model(resnet_test, test_loader, device)\n",
        "print(f'Test Accuracy of the model on the 10000 test images: {test_accuracy:.2f}%')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfYC56dhLO8u"
      },
      "source": [
        "# Hippocampus Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "BLWq-gNEtX_6"
      },
      "outputs": [],
      "source": [
        "# define HC\n",
        "\n",
        "class HC(nn.Module):\n",
        "  def __init__(self, classifier_dims = Classifier_Dims, learning_rate= Learning_Rate, p_dropout=Dropout):\n",
        "    super(HC, self).__init__()\n",
        "\n",
        "    self.short_term_memory = FeatureDataset()\n",
        "\n",
        "    classifier_layers = []\n",
        "    current_dim = classifier_dims[0]\n",
        "\n",
        "    if len(classifier_dims)!=1:\n",
        "      # Avoid dropping out the first layer of processing and output layer\n",
        "      classifier_layers.append(nn.Linear(current_dim, classifier_dims[0]))\n",
        "      classifier_layers.append(nn.ReLU())\n",
        "\n",
        "      for i in range(1, len(classifier_dims)-1):\n",
        "        hidden_dim = classifier_dims[i]\n",
        "        classifier_layers.append(nn.Linear(current_dim, hidden_dim))\n",
        "        classifier_layers.append(nn.ReLU())\n",
        "        classifier_layers.append(nn.Dropout(p=p_dropout))\n",
        "        current_dim = hidden_dim\n",
        "\n",
        "    classifier_layers.append(nn.Linear(current_dim, classifier_dims[len(classifier_dims)-1]))\n",
        "\n",
        "    self.classifier = nn.Sequential(*classifier_layers)\n",
        "\n",
        "    # Using Adam Optimizer\n",
        "    self.optimizer = optim.Adam(self.parameters(), lr = learning_rate)\n",
        "    self.CrossEntropyLoss = nn.CrossEntropyLoss()\n",
        "\n",
        "  def forward(self, x, is_storing = False):\n",
        "    if (is_storing):\n",
        "      features = x[0].squeeze()\n",
        "      labels = x[1].squeeze()\n",
        "      self.short_term_memory.add_features(features, labels)\n",
        "    class_logits = self.classifier(x)\n",
        "    return class_logits\n",
        "\n",
        "  def clear_memory(self):\n",
        "    memory = self.short_term_memory\n",
        "    self.short_term_memory = FeatureDataset()\n",
        "    return memory\n",
        "\n",
        "  def training_step(self, dataloader):\n",
        "    total_loss = 0\n",
        "\n",
        "    self.train()\n",
        "    optimizer = self.optimizer\n",
        "\n",
        "    for features, targets in dataloader:\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      class_logits = self.forward(features, is_storing=True)\n",
        "      loss = self.CrossEntropyLoss(class_logits, targets)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      total_loss += loss\n",
        "\n",
        "    return (total_loss / (len(dataloader) * dataloader.batch_size))\n",
        "\n",
        "  def calc_accuracy(self, dataloader):\n",
        "    total_correct = 0\n",
        "\n",
        "    self.eval()\n",
        "    with torch.no_grad():\n",
        "      for features, targets in dataloader:\n",
        "        predictions = self.forward(features, is_storing=False)\n",
        "        predictions = torch.argmax(predictions, dim=1)\n",
        "\n",
        "        correct = (predictions == targets).sum().item()\n",
        "        total_correct += correct\n",
        "\n",
        "    return (total_correct / (len(dataloader) * dataloader.batch_size))*100\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "\n",
        "hippocampus = HC()\n",
        "hippocampus.to(device)\n",
        "\n",
        "loss_history = []\n",
        "for epoch in range(50):\n",
        "  loss = hippocampus.training_step(train_loader_processed)\n",
        "  loss_history.append(loss)\n",
        "  accuracy = hippocampus.calc_accuracy(train_loader_processed)\n",
        "  print(f\"Epoch {epoch+1}: Loss is {loss:.4f}, Accuracy is {accuracy:.4f}%\")\n",
        "\n",
        "print(f\"Accuracy is {hippocampus.calc_accuracy(test_loader_processed):.4f}%\")"
      ],
      "metadata": {
        "id": "GKPmSaeDjyHn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "8c3053a5-8aab-4199-da9e-2dd86136f52e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss is 4.6347, Accuracy is 2.2540\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-7d836b81bfeb>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhippocampus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader_processed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mloss_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhippocampus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader_processed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}: Loss is {loss:.4f}, Accuracy is {accuracy:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-02527180277b>\u001b[0m in \u001b[0;36mcalc_accuracy\u001b[0;34m(self, dataloader)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_storing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \"\"\"\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcollate_fn_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0melem_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcollate_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typed_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iAOTMobLSnf"
      },
      "source": [
        "# Pre-frontal Cortex  Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "9213wTvFtRdp"
      },
      "outputs": [],
      "source": [
        "# define mPFC (long term)\n",
        "\n",
        "class mPFC(nn.Module):\n",
        "  def __init__(self, input_dim=2048, autoencoder_hidden_dims = np.array([1024, 512]), classifier_dims = np.array([100]), lambda_values=[1e4, 1, 0.1], learning_rate=5e-4):\n",
        "    super(mPFC, self).__init__()\n",
        "    # encoder\n",
        "    encoder_layers = []\n",
        "    current_dim = input_dim\n",
        "    encoder_layers.append(nn.ELU())\n",
        "    for hidden_dim in autoencoder_hidden_dims:\n",
        "      encoder_layers.append(nn.Linear(current_dim, hidden_dim))\n",
        "      encoder_layers.append(nn.ELU())\n",
        "      current_dim = hidden_dim\n",
        "    self.encoder = nn.Sequential(*encoder_layers)\n",
        "\n",
        "    # decoder\n",
        "    decoder_layers = []\n",
        "    hidden_dims_reversed = list(autoencoder_hidden_dims[::-1])\n",
        "    for hidden_dim in hidden_dims_reversed:\n",
        "      decoder_layers.append(nn.Linear(current_dim, hidden_dim))\n",
        "      decoder_layers.append(nn.ELU())\n",
        "      current_dim = hidden_dim\n",
        "    decoder_layers.append(nn.Linear(current_dim, input_dim))\n",
        "    decoder_layers.append(nn.ELU())\n",
        "    self.decoder = nn.Sequential(*decoder_layers)\n",
        "\n",
        "    #classifier\n",
        "    current_dim = autoencoder_hidden_dims[-1]\n",
        "    classifier_layers= []\n",
        "\n",
        "    if len(classifier_dims) != 1:\n",
        "      classifier_layers.append(nn.Linear(current_dim, classifier_dims[0]))\n",
        "      classifier_layers.append(nn.ELU())\n",
        "      current_dim = classifier_dims[0]\n",
        "\n",
        "      for i in range(1, len(classifier_dims)-1):\n",
        "        hidden_dim = classifier_dims[i]\n",
        "        classifier_layers.append(nn.Linear(current_dim, hidden_dim))\n",
        "        classifier_layers.append(nn.ELU())\n",
        "        classifier_layers.append(nn.Dropout(p=Dropout))\n",
        "        current_dim = hidden_dim\n",
        "\n",
        "    classifier_layers.append(nn.Linear(current_dim, classifier_dims[len(classifier_dims)-1]))\n",
        "\n",
        "    self.classifier = nn.Sequential(*classifier_layers)\n",
        "\n",
        "    # lambda\n",
        "    self.lambda_values = torch.tensor(lambda_values if lambda_values else [1.0] * len(autoencoder_hidden_dims), dtype=torch.float32)\n",
        "\n",
        "    # optimizer\n",
        "    self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
        "\n",
        "    #session number\n",
        "    self.class_means = defaultdict(dict)\n",
        "    self.class_covariances = defaultdict(dict)\n",
        "\n",
        "  def encoder_forward(self, x):\n",
        "    encoder_intermediates = [x]\n",
        "    for layer in self.encoder:\n",
        "      x = layer(x)\n",
        "      encoder_intermediates.append(x)\n",
        "    encoded = encoder_intermediates[-1]\n",
        "    return encoded, encoder_intermediates\n",
        "\n",
        "  def decoder_forward(self, x):\n",
        "    decoder_intermediates = [x]\n",
        "    for layer in self.decoder:\n",
        "      x = layer(x)\n",
        "      decoder_intermediates.append(x)\n",
        "    pseudo_img = decoder_intermediates[-1]\n",
        "    return pseudo_img, list(decoder_intermediates[::-1])\n",
        "\n",
        "  def classify(self, x):\n",
        "    class_logits = self.classifier(x)\n",
        "    return class_logits\n",
        "\n",
        "  def compute_loss(self, class_logits, targets, encoder_intermediates, decoder_intermediates):\n",
        "    # classification loss\n",
        "    classification_loss = nn.CrossEntropyLoss()(class_logits, targets)\n",
        "\n",
        "    # reconstruction loss with lambda weighting\n",
        "    reconstruction_loss = 0\n",
        "    for i in range(len(self.lambda_values)):\n",
        "      encoder_hidden = encoder_intermediates[i]\n",
        "      decoder_hidden = decoder_intermediates[i]\n",
        "      diff = encoder_hidden - decoder_hidden\n",
        "      squared_diff = diff.pow(2)\n",
        "      layer_loss = squared_diff.sum()\n",
        "      reconstruction_loss += self.lambda_values[i] * layer_loss\n",
        "\n",
        "    # total loss\n",
        "    total_loss = classification_loss + reconstruction_loss\n",
        "\n",
        "    return classification_loss, reconstruction_loss, total_loss\n",
        "\n",
        "  def training_step(self, data_loader, device):\n",
        "    self.train()\n",
        "\n",
        "    total_classification_loss = 0\n",
        "    total_reconstruction_loss = 0\n",
        "    total_total_loss = 0\n",
        "\n",
        "    for x, targets in data_loader:\n",
        "      x, targets = x.to(device), targets.to(device)\n",
        "\n",
        "      # forward pass\n",
        "      encoded, encoder_intermediates = self.encoder_forward(x)\n",
        "      pseudo_img, decoder_intermediates = self.decoder_forward(encoded)\n",
        "      class_logits = self.classify(encoded)\n",
        "\n",
        "      # compute losses\n",
        "      classification_loss, reconstruction_loss, total_loss = self.compute_loss(\n",
        "        class_logits, targets, encoder_intermediates, decoder_intermediates\n",
        "      )\n",
        "\n",
        "      # zero gradients\n",
        "      self.optimizer.zero_grad()\n",
        "\n",
        "      # backward pass\n",
        "      classification_loss.backward(retain_graph=True)\n",
        "      classifier_grads = {name: param.grad.clone() for name, param in self.classifier.named_parameters()}\n",
        "      reconstruction_loss.backward(retain_graph=True)\n",
        "      decoder_grads = {name: param.grad.clone() for name, param in self.decoder.named_parameters()}\n",
        "      total_loss.backward()\n",
        "      encoder_grads = {name: param.grad.clone() for name, param in self.encoder.named_parameters()}\n",
        "\n",
        "      # optimizer\n",
        "      encoder_optimizer = optim.Adam(self.encoder.parameters(), lr=self.optimizer.defaults['lr'])\n",
        "      encoder_optimizer.step()\n",
        "      classifier_optimizer = optim.Adam(self.classifier.parameters(), lr=self.optimizer.defaults['lr'])\n",
        "      classifier_optimizer.step()\n",
        "      decoder_optimizer = optim.Adam(self.decoder.parameters(), lr=self.optimizer.defaults['lr'])\n",
        "      decoder_optimizer.step()\n",
        "\n",
        "      # update parameters\n",
        "      for name, param in self.classifier.named_parameters():\n",
        "        if param.grad is not None:\n",
        "          param.grad.data = classifier_grads[name].data\n",
        "      for name, param in self.decoder.named_parameters():\n",
        "        if param.grad is not None:\n",
        "          param.grad.data = decoder_grads[name].data\n",
        "      for name, param in self.encoder.named_parameters():\n",
        "        if param.grad is not None:\n",
        "          param.grad.data = encoder_grads[name].data\n",
        "\n",
        "      # add losses to total\n",
        "      total_classification_loss += classification_loss.item()\n",
        "      total_reconstruction_loss += reconstruction_loss.item()\n",
        "      total_total_loss += total_loss.item()\n",
        "\n",
        "    # average loss\n",
        "    average_classification_loss = total_classification_loss / len(data_loader)\n",
        "    average_reconstruction_loss = total_reconstruction_loss / len(data_loader)\n",
        "    average_total_loss = total_total_loss / len(data_loader)\n",
        "\n",
        "    return average_classification_loss, average_reconstruction_loss, average_total_loss\n",
        "\n",
        "  def consolidate_statistics(self):\n",
        "    # compute the average mean vector and covariance matrix for each class\n",
        "    for label in self.class_means:\n",
        "      if self.class_means[label]:\n",
        "        means = torch.stack(self.class_means[label])\n",
        "        covariances = torch.stack(self.class_covariances[label])\n",
        "\n",
        "        # average the mean vectors and covariance matrices\n",
        "        consolidated_mean = means.mean(dim=0)\n",
        "        consolidated_covariance = covariances.mean(dim=0)\n",
        "\n",
        "        # update the consolidated statistics\n",
        "        self.class_means[label] = consolidated_mean\n",
        "        self.class_covariances[label] = consolidated_covariance\n",
        "\n",
        "  def generate_statistics(self, feature_vectors, labels, device):\n",
        "    # current session class statistics\n",
        "    class_features = defaultdict(list)\n",
        "\n",
        "    for feature, label in zip(feature_vectors, labels):\n",
        "      class_features[label.item()].append(feature)\n",
        "\n",
        "    for label, features in class_features.items():\n",
        "      features = torch.stack(features).to(device)\n",
        "      mean_vector = features.mean(dim=0)\n",
        "      centered_features = features - mean_vector\n",
        "      covariance_matrix = torch.mm(centered_features.t(), centered_features) / (features.size(0) - 1)\n",
        "\n",
        "      # append the current session's statistics\n",
        "      self.class_means[label].append(mean_vector)\n",
        "      self.class_covariances[label].append(covariance_matrix)\n",
        "\n",
        "      self.consolidate_statistics()\n",
        "\n",
        "  def pseudoimg_from_statistics(self, num_examples_per_class, device):\n",
        "    self.eval()\n",
        "\n",
        "    pseudo_examples = []\n",
        "    pseudo_labels = []\n",
        "\n",
        "    for label, mean_vector in self.class_means.items():\n",
        "      if isinstance(mean_vector, torch.Tensor):\n",
        "        covariance_matrix = self.class_covariances[label]\n",
        "\n",
        "        # create a multivariate normal distribution\n",
        "        mvn = dist.MultivariateNormal(mean_vector, covariance_matrix)\n",
        "\n",
        "        # generate pseudo-examples\n",
        "        examples = mvn.sample((num_examples_per_class,)).to(device)\n",
        "        labels = torch.full((num_examples_per_class,), label, dtype=torch.long, device=device)\n",
        "\n",
        "        pseudo_examples.append(examples)\n",
        "        pseudo_labels.append(labels)\n",
        "\n",
        "    pseudo_examples = torch.cat(pseudo_examples)\n",
        "    pseudo_labels = torch.cat(pseudo_labels)\n",
        "\n",
        "    return pseudo_examples, pseudo_labels\n",
        "\n",
        "  def calculate_accuracy(self, data_loader, device):\n",
        "    self.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for x, targets in data_loader:\n",
        "        x, targets = x.to(device), targets.to(device)\n",
        "        encoded, _ = self.encoder_forward(x)\n",
        "        class_logits = self.classify(encoded)\n",
        "        _, predicted = torch.max(class_logits.data, 1)\n",
        "        total += targets.size(0)\n",
        "        correct += (predicted == targets).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy\n",
        "\n",
        "mPFC = mPFC()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKg46QH1Lefr"
      },
      "source": [
        "# BLA Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JGy_SZT9tdgY"
      },
      "outputs": [],
      "source": [
        "# Define BLA\n",
        "\n",
        "class BLA(nn.Module):\n",
        "\n",
        "  def __init__(self, classifier_dims = Classifier_Dims, learning_rate= Learning_Rate, p_dropout=Dropout):\n",
        "    super(BLA, self).__init__()\n",
        "\n",
        "    classifier_layers = []\n",
        "    current_dim = classifier_dims[0]\n",
        "\n",
        "    if len(classifier_dims)!=1:\n",
        "      # Avoid dropping out the first layer of processing and output layer\n",
        "      classifier_layers.append(nn.Linear(current_dim, classifier_dims[0]))\n",
        "      classifier_layers.append(nn.ReLU())\n",
        "\n",
        "      for i in range(1, len(classifier_dims)):\n",
        "        hidden_dim = classifier_dims[i]\n",
        "        classifier_layers.append(nn.Linear(current_dim, hidden_dim))\n",
        "        classifier_layers.append(nn.ReLU())\n",
        "        classifier_layers.append(nn.Dropout(p=p_dropout))\n",
        "        current_dim = hidden_dim\n",
        "\n",
        "    classifier_layers.append(nn.Linear(current_dim, 1))\n",
        "\n",
        "    self.classifier = nn.Sequential(*classifier_layers)\n",
        "\n",
        "    # Using Adam Optimizer\n",
        "    self.optimizer = optim.Adam(self.parameters(), lr = learning_rate)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    class_logits = self.classifier(x)\n",
        "    return class_logits\n",
        "\n",
        "  def training_step(self, dataloader, HC, mPFC):\n",
        "    total_loss = 0\n",
        "\n",
        "    self.train()\n",
        "    HC.eval()\n",
        "    mPFC.eval()\n",
        "    for features, label in dataloader:\n",
        "      HC_logits = []\n",
        "      mPFC_logits = []\n",
        "\n",
        "      with torch.no_grad():\n",
        "        HC_logits = HC.forward(features)\n",
        "        mPFC_logits = mPFC.forward(features)\n",
        "\n",
        "      optimizer = self.optimizer\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      class_prob = self.Softmax(self.forward(features))\n",
        "\n",
        "      HC_prob = nn.Softmax(HC_logits)\n",
        "      mPFC_prob = nn.Softmax(mPFC_logits)\n",
        "\n",
        "      loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "      HC_loss = loss_fn(HC_prob, labels)\n",
        "      mPFC_loss = loss_fn(mPFC_prob, labels)\n",
        "\n",
        "      # Determine if HC or mPFC is more accurate\n",
        "      target_is_HC = HC_loss > mPFC_loss\n",
        "      target_is_HC = target_is_HC.float().view(-1, 1)  # Convert to float and reshape for broadcasting\n",
        "\n",
        "      # Calculate the BLA loss based on whether the prediction aligns with the more accurate model\n",
        "      BLA_target = target_is_HC\n",
        "      BLA_loss = nn.BCELoss()(class_prob, BLA_target)\n",
        "\n",
        "      BLA_loss.backwards()\n",
        "      optimizer.step()\n",
        "\n",
        "      total_loss += BLA_loss\n",
        "\n",
        "    return (total_loss / (len(dataloader) * dataloader.batch_size))\n",
        "\n",
        "Bla = BLA()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_M6temMLhK_"
      },
      "source": [
        "# Dual Memory System Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "7_dX6yZDtixQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "9e74b3c4-705f-44d6-fee1-a539f51416ce"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "Module [mPFC] is missing the required \"forward\" function",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-af9e618dd0ad>\u001b[0m in \u001b[0;36m<cell line: 74>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcombined_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m \u001b[0mDMSM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDMSM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-af9e618dd0ad>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dim, classifier_dims, learning_rate, p_dropout, lambda_values)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mInput_Dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassifier_Dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLearning_Rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_dropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1e4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDMSM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmPFC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmPFC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_dropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBLA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_forward_unimplemented\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mregistered\u001b[0m \u001b[0mhooks\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlatter\u001b[0m \u001b[0msilently\u001b[0m \u001b[0mignores\u001b[0m \u001b[0mthem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m     \"\"\"\n\u001b[0;32m--> 351\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Module [{type(self).__name__}] is missing the required \\\"forward\\\" function\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: Module [mPFC] is missing the required \"forward\" function"
          ]
        }
      ],
      "source": [
        "# dmsm\n",
        "\n",
        "class DMSM(nn.Module):\n",
        "  def __init__(self, input_dim=Input_Dim, classifier_dims = Classifier_Dims, learning_rate=Learning_Rate, p_dropout=Dropout, lambda_values = [1e4, 1.0, 0.1]):\n",
        "    super(DMSM, self).__init__()\n",
        "    self.mPFC = mPFC(input_dim, np.array([1024, 512]), classifier_dims, lambda_values, learning_rate)\n",
        "    self.HC = HC(classifier_dims, learning_rate, p_dropout)\n",
        "    self.BLA()\n",
        "\n",
        "  def training(self, dataloader, HC_epochs = HC_Epochs, BLA_epochs = BLA_Epochs):\n",
        "    mPFC = self.mPFC\n",
        "    HC = self.HC\n",
        "    BLA = self.BLA\n",
        "\n",
        "    HC_loss_history = []\n",
        "    BLA_loss_history = []\n",
        "\n",
        "    # Train HC\n",
        "    for epoch in range(HC_epochs):\n",
        "      HC_loss_history.append(HC.training_step(dataloader))\n",
        "\n",
        "    # Integrate hallucinated images into the dataloader\n",
        "\n",
        "\n",
        "    # Train BLA\n",
        "    for epoch in range(BLA_epochs):\n",
        "      BLA_loss_history.append(BLA.training_step(dataloader))\n",
        "\n",
        "    return HC_loss_history, BLA_loss_history\n",
        "\n",
        "  def sleep(self, mPFC_Epochs = mPFC_Epochs):\n",
        "    mPFC = self.mPFC\n",
        "    HC = self.HC\n",
        "    BLA = self.BLA\n",
        "\n",
        "    mPFC_loss_history = []\n",
        "\n",
        "    short_term_data = HC.clear_memory()\n",
        "\n",
        "    # Integrate hallucinated images into short term memory data\n",
        "    #\n",
        "    #\n",
        "    #\n",
        "    #\n",
        "\n",
        "    for epoch in range(mPFC_Epochs):\n",
        "      mPFC_Epochs.training_step()\n",
        "\n",
        "  def eval(self, dataloader):\n",
        "    mPFC = self.mPFC\n",
        "    HC = self.HC\n",
        "    BLA = self.BLA\n",
        "\n",
        "    HC.eval()\n",
        "    mPFC.eval()\n",
        "    BLA.eval()\n",
        "\n",
        "    predictions = BLA.forward(dataloader)\n",
        "    predictions_rounded = torch.round(predictions)\n",
        "\n",
        "    HC_mask = (predictions_rounded == 0).squeeze()\n",
        "    mPFC_mask = (predictions_rounded == 1).squeeze()\n",
        "\n",
        "    HC_output = HC.forward(dataloader[HC_mask])\n",
        "    mPFC_output = mPFC.forward(dataloader[mPFC_mask])\n",
        "\n",
        "    # Combine the results\n",
        "    combined_output = torch.zeros_like(hc_predictions)\n",
        "    combined_output[HC_mask] = HC_output\n",
        "    combined_output[mPFC_mask] = mPFC_output\n",
        "\n",
        "    return combined_output\n",
        "\n",
        "DMSM = DMSM()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKJvA-5lt9N1"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}