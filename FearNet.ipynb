{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SquirrelLover/FearNet-Implementation/blob/main/FearNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj2K6Qs9s9bn"
      },
      "source": [
        "Implementation of a Fearnet Variation\n",
        "\n",
        "Authors: Brady Gho, Lucy Wu\n",
        "\n",
        "Source: https://arxiv.org/abs/1711.10563\n",
        "\n",
        "Created on July 25, 2024. Last edited August 2, 2024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pxb1oT_wLvLv"
      },
      "source": [
        "# Defining Imports and Meta-parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ir8RTlFR2G9X"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.distributions as dist\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "import pdb\n",
        "\n",
        "import gc\n",
        "\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hR2-6d6qtZY6"
      },
      "outputs": [],
      "source": [
        "# Define meta-Parameters\n",
        "Mini_batch = 100\n",
        "Dropout = 0.5\n",
        "Autoencoder_Hidden_Dims = np.array([1024, 512])\n",
        "mPFC_Classifier_Dims = [100]\n",
        "Classifier_Dims = np.array([2048, 600, 100])\n",
        "Lambda_Values = [1e4, 1, 0.1]\n",
        "Input_Dim = 2048\n",
        "Learning_Rate = 5e-4\n",
        "Mem_Cons_Epochs = 10\n",
        "mPFC_Base_Epochs = 20\n",
        "BLA_Epochs = 10\n",
        "sleep_frequency = 5\n",
        "\n",
        "torch.manual_seed(42) # seed set for reproducibility"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdVa6JvuLHcT"
      },
      "source": [
        "# Loading and Processing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "8xFkEuoHs45K",
        "outputId": "1d5f7f59-8a92-48c2-8d56-0e86dd2e0abd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Train Loader Images:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x400 with 4 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABOwAAAE3CAYAAAAZhN7OAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABhlklEQVR4nO39efRnVXXn/7/uve/7nj9zfWoegGKSSRB0aVQmEw1xaCVp05o2irE7HduOnZiYXjFGsA3ddtqEdIzdLnFIA7aJJF9j1JYmgvqLMSIGBEWQoaii5s88vsd7z+8PQsUS2fsSEN586vlYK2vF2qf2uffcc/Y999SHqiiEEAQAAAAAAABgIMRP9wUAAAAAAAAA+Ccc2AEAAAAAAAADhAM7AAAAAAAAYIBwYAcAAAAAAAAMEA7sAAAAAAAAgAHCgR0AAAAAAAAwQDiwAwAAAAAAAAYIB3YAAAAAAADAAOHADgAAAAAAABggHNjhcVteXtZb3vIWbdy4UVEU6T/+x//4hPJdeOGFuvDCC5+UawOApwq1EAAeRj0EAGohnnwc2BXwiU98QlEU6dZbb326L2UgXHnllfrEJz6hX/mVX9E111yjN7zhDU/3JT3p7r77br3zne/U2WefraGhIW3atEkvf/nLf+QcOO644xRF0Y/8v5NOOulpuHrgx4NaeLRjoRZK0u/93u/pVa96lTZs2KAoinT55Zc/Ztt9+/bpta99rUZHRzU8PKx/8S/+hR544IGn7mKBpwj18GjHQj28/PLLH3O/F0WRvva1rx1p+5GPfEQXXHCBNmzYoEqlouOPP16XXXaZHnzwwafvBoAfA2rh0Y6FWvjggw8+Zh381Kc+dVTbW265RW9961t17rnnKk1TRVH0NF31M1fp6b4APPPcdNNNev7zn6/3vOc9T/el/NhcffXV+uhHP6qf/dmf1Vvf+lYtLCzowx/+sJ7//Ofri1/8on7yJ3/ySNurrrpKy8vLR/3+3bt363d+53f00pe+9Km+dABPkWOhFkrS7/zO72jjxo0655xzdMMNNzxmu+XlZV100UVaWFjQb//2bytNU/3hH/6hLrjgAt1+++2amJh4Cq8awFPpWKiHl156qU488cRH/fpv//Zva3l5Wc997nOP/Nptt92m448/Xq961as0NjamXbt26SMf+Yg+97nP6dvf/rY2b978VF46gKfIsVALH/G6171OP/MzP3PUr73gBS846n9/4Qtf0NVXX62zzjpLJ5xwgr7//e8/lZe4JnBgh8ft8OHDOu20057uy/ixet3rXqfLL79czWbzyK+9+c1v1rOe9SxdfvnlRx3YvfrVr37U73/f+94nSfqFX/iFH/u1Anh6HAu1UJJ27dql4447TtPT05qcnHzMdh/60Id077336pZbbjny4XrJJZfojDPO0Ac+8AFdeeWVT9UlA3iKHQv18KyzztJZZ5111K899NBD2rt3r97ylreoXC4f+fUPfehDj/r9r371q3Xeeefpf//v/63/9J/+04/9egE89Y6FWviI5zznOfrX//pfm21+5Vd+Rb/1W7+lWq2mt73tbRzY/TPwn8T+M73pTW9Ss9nUnj179IpXvELNZlNbtmzRn/zJn0iS7rzzTl188cVqNBrasWOHPvnJTx71+2dnZ/Ubv/EbOvPMM9VsNjU8PKxLLrlE3/72tx/V1+7du/WqV71KjUZD69ev16/92q/phhtuUBRF+vKXv3xU22984xv66Z/+aY2MjKher+uCCy446kf0LYcPH9Yv/dIvacOGDapWq3r2s5+tP/3TPz0S//KXv6woirRr1y59/vOfP/Kjr96P91977bV63vOep3q9rrGxMZ1//vn6f//v/z1m+263q9/93d/Vueeeq5GRETUaDb34xS/WzTff/Ki2n/rUp3TuuedqaGhIw8PDOvPMM/VHf/RHR+K9Xk9XXHGFTjrpJFWrVU1MTOhFL3qRbrzxRvOazz333KMO6yRpYmJCL37xi/W9733P/L2S9MlPflLHH3+8fuInfsJtCzyTUQvXdi2UHv7P/ou4/vrr9dznPveonzI59dRT9ZKXvER//ud/XigH8ExGPVz79fCH/Z//838UQij0B7SP1NL5+fnH3Q/wTEItPHZq4crKirrd7mPGN2zYoFqtVjgfHo0DuycgyzJdcskl2rZtm/7bf/tvOu644/S2t71Nn/jEJ/TTP/3TOu+88/T+979fQ0ND+sVf/EXt2rXryO994IEH9JnPfEaveMUr9Ad/8Af6zd/8Td1555264IILtH///iPtVlZWdPHFF+tv/uZv9Ku/+qt617vepb/7u7/Tb/3Wbz3qem666Sadf/75Wlxc1Hve8x5deeWVmp+f18UXX6xbbrnFvJdWq6ULL7xQ11xzjX7hF35Bv//7v6+RkRG96U1vOrKwn/WsZ+maa67RunXrdPbZZ+uaa67RNddcY/7ExRVXXKE3vOENStNU733ve3XFFVdo27Ztuummmx7z9ywuLurqq6/WhRdeqPe///26/PLLNTU1pZe97GW6/fbbj7S78cYb9brXvU5jY2N6//vfr//6X/+rLrzwwqMK7+WXX64rrrhCF110kT74wQ/qXe96l7Zv365/+Id/MMfjsRw8eFDr1q0z29x222363ve+p9e//vX/rD6AZxpq4bFXC39Ynue64447dN555z0q9rznPU/333+/lpaWnpS+gEFGPTy26uF1112nbdu26fzzz/+R8ZmZGR0+fFi33nqrLrvsMknSS17yksfdD/BMQy1c+7XwiiuuULPZVLVa1XOf+1zzoBFPQIDr4x//eJAUvvnNbx75tTe+8Y1BUrjyyiuP/Nrc3Fyo1WohiqLwqU996siv33333UFSeM973nPk19rtdsiy7Kh+du3aFSqVSnjve9975Nc+8IEPBEnhM5/5zJFfa7Va4dRTTw2Sws033xxCCCHP83DSSSeFl73sZSHP8yNtV1dXw/HHHx9+6qd+yrzHq666KkgK11577ZFf63a74QUveEFoNpthcXHxyK/v2LEjvPzlLzfzhRDCvffeG+I4Dq95zWseda8/eI0XXHBBuOCCC478736/HzqdzlHt5+bmwoYNG8Kb3/zmI7/29re/PQwPD4d+v/+Y1/DsZz+70LUW8dWvfjVEURTe/e53m+3e8Y53BEnhrrvuelL6BQYFtfDYroVTU1OPen4/HPvBZ/aIP/mTPwmSwt133/2E+gcGCfXw2K6HIYTwne98J0gK73znOx+zTaVSCZKCpDAxMRH+x//4H0+4X2CQUAuPvVq4e/fu8NKXvjT8z//5P8NnP/vZcNVVV4Xt27eHOI7D5z73ucf8ff/+3//7wPHT48dP2D1Bb3nLW478/6OjozrllFPUaDT02te+9sivn3LKKRodHT3qX8qrVCqK44eHP8syzczMqNls6pRTTjnqVPuLX/yitmzZole96lVHfq1arerf/Jt/c9R13H777br33nv1+te/XjMzM5qentb09LRWVlb0kpe8RF/96leV5/lj3scXvvAFbdy4Ua973euO/FqapvrVX/1VLS8v6ytf+crjHpvPfOYzyvNcv/u7v3vkXh9h/QsxSZIc+XtA8jzX7Oys+v2+zjvvvKPGZnR0VCsrK+aP7Y6Ojuq73/2u7r333sd9/T/o8OHDev3rX6/jjz9e73znOx+zXZ7n+tSnPqVzzjlHz3rWs55Qn8AzCbXwsa2lWvhYWq2WpIef5w+rVqtHtQHWOurhY1tL9fC6666TZP99xf/3//5ffeELX9AHPvABbd++XSsrK0+oT+CZhFr42J7JtXD79u264YYb9O/+3b/TK1/5Sr397W/XbbfdpsnJSb3jHe94XLng48DuCahWq4/6MdeRkRFt3br1UQttZGREc3NzR/53nuf6wz/8Q5100kmqVCpat26dJicndccdd2hhYeFIu927d2vnzp2PyvfD/0rVIwvtjW98oyYnJ4/6v6uvvlqdTueovD9s9+7dOumkkx5VMB45dNq9e7c3HI9y//33K47jf9ZfvPmnf/qnOuuss4789/STk5P6/Oc/f9Q9vPWtb9XJJ5+sSy65RFu3btWb3/xmffGLXzwqz3vf+17Nz8/r5JNP1plnnqnf/M3f1B133PG4rmVlZUWveMUrtLS0pL/6q7961N9t94O+8pWvaN++ffxjEzimUAtta6UWWh75+0k6nc6jYu12+6g2wFpGPbStlXoYQtAnP/lJnXHGGY/6hyh+0EUXXaRLLrlEv/7rv65Pf/rTuuKKK/TBD37w8d048AxELbStlVr4iPHxcV122WW65557tHfv3n9WDvxoHNg9AUmSPK5fDyEc+f+vvPJK/fqv/7rOP/98XXvttbrhhht044036vTTTzdP+B/LI7/n93//93XjjTf+yP+zDpoGybXXXqs3velN2rlzpz760Y/qi1/8om688UZdfPHFR43N+vXrdfvtt+uzn/2sXvWqV+nmm2/WJZdcoje+8Y1H2px//vm6//779bGPfUxnnHGGrr76aj3nOc/R1VdfXehaut2uLr30Ut1xxx36q7/6K51xxhlm++uuu05xHB/1JzDAWkct/PEYpFroGR8fV6VS0YEDBx4Ve+TXNm/e/KT0BQwy6uGPx6DVw6997WvavXv34/oD2p07d+qcc8458pN5wFpGLfzxGLRa+IO2bdsm6eF/NARPntLTfQHHquuvv14XXXSRPvrRjx716/Pz80f9owY7duzQXXfdpRDCUX96cN999x31+3bu3ClJGh4e1k/+5E8+7uvZsWOH7rjjDuV5ftSfHtx9991H4o/Xzp07lee57rrrLp199tmFf9/111+vE044QX/5l3951D2/5z3veVTbcrmsV77ylXrlK1+pPM/11re+VR/+8If17ne/+8ifrjxy4n/ZZZdpeXlZ559/vi6//PKjfkz7R8nzXL/4i7+oL33pS/rzP/9zXXDBBWb7Tqejv/iLv9CFF17IhylQELXwsQ1KLSwijmOdeeaZuvXWWx8V+8Y3vqETTjhBQ0NDT7gfYC2jHj62QauH1113naIoetz/wFir1fqRP4kM4J9QCx/boNXCH/TIf9Zs/UMbePz4CbunSZIkR/1JgiR9+tOf1r59+476tZe97GXat2+fPvvZzx75tXa7rY985CNHtTv33HO1c+dO/ff//t+1vLz8qP6mpqbM6/mZn/kZHTx4UH/2Z3925Nf6/b7++I//WM1m0z2s+lFe/epXK45jvfe9733Un4b88L3/oEf+5OUH23zjG9/Q17/+9aPazczMHPW/4zg+8p8lPLIZ+uE2zWZTJ554YqHN0n/4D/9Bf/Znf6YPfehDuvTSS932X/jCFzQ/P89/Dgs8DtTCwa+FRf3cz/2cvvnNbx51aHfPPffopptu0r/8l//ySesHWKuoh8+Metjr9fTpT39aL3rRi7R9+/ZHxfv9/lH/ed8jbrnlFt15550/8l/TBvBPqIWDXQt/1Hjt27dPH/vYx3TWWWdp06ZN5u/H48NP2D1NXvGKV+i9732vLrvsMv3ET/yE7rzzTl133XU64YQTjmr3y7/8y/rgBz+o173udXr729+uTZs26brrrjvyl3g/crIex7GuvvpqXXLJJTr99NN12WWXacuWLdq3b59uvvlmDQ8P66//+q8f83r+7b/9t/rwhz+sN73pTfrWt76l4447Ttdff72+9rWv6aqrrvpn/WTEiSeeqHe96136z//5P+vFL36xLr30UlUqFX3zm9/U5s2b9V/+y395zLH5y7/8S73mNa/Ry1/+cu3atUv/63/9L5122mlHFdm3vOUtmp2d1cUXX6ytW7dq9+7d+uM//mOdffbZR/5OgdNOO00XXnihzj33XI2Pj+vWW2/V9ddfr7e97W3mtV911VX60Ic+pBe84AWq1+u69tprj4q/5jWvUaPROOrXrrvuOlUqFf3sz/7s4x4r4FhFLRzsWihJ11xzjXbv3q3V1VVJ0le/+lW9733vkyS94Q1vOPIny29961v1kY98RC9/+cv1G7/xG0rTVH/wB3+gDRs28JcQAwVQDwe/HkrSDTfcoJmZmcf8A9rl5WVt27ZNP//zP6/TTz9djUZDd955pz7+8Y9rZGRE7373ux/nqAHHFmrhYNfCd77znbr//vv1kpe8RJs3b9aDDz6oD3/4w1pZWdEf/dEfHdV29+7duuaaayTpyB/oPrKH3LFjh97whjc87rE75jyl/ybtM9Rj/XPVjUbjUW0vuOCCcPrppz/q13/4n3hut9vhHe94R9i0aVOo1WrhhS98Yfj617/+qH+6OYQQHnjggfDyl7881Gq1MDk5Gd7xjneEv/iLvwiSwt///d8f1fa2224Ll156aZiYmAiVSiXs2LEjvPa1rw1f+tKX3Ps8dOhQuOyyy8K6detCuVwOZ555Zvj4xz/u3ovnYx/7WDjnnHNCpVIJY2Nj4YILLgg33njjkfgP33Oe5+HKK68MO3bsCJVKJZxzzjnhc5/7XHjjG98YduzYcaTd9ddfH1760peG9evXh3K5HLZv3x5++Zd/ORw4cOBIm/e9733hec97XhgdHQ21Wi2ceuqp4fd+7/dCt9s1r/mRf478sf5v165dR7VfWFgI1Wo1XHrppYXHBXimoRba9+J5JtbCR67rsWrhzTfffFTbhx56KPzcz/1cGB4eDs1mM7ziFa8I9957b+ExAp4pqIf2vXieqfUwhBD+1b/6VyFN0zAzM/Mj451OJ7z97W8PZ511VhgeHg5pmoYdO3aEX/qlX3rU/hF4pqMW2vfieSbWwk9+8pPh/PPPD5OTk6FUKoV169aF17zmNeFb3/rWo9refPPNj7mH/OFniR8tCsH4mUsMrKuuukq/9mu/pr1792rLli1P9+UAwNOCWggAD6MeAgC1EGsLB3bPAK1WS7Va7cj/brfbOuecc5Rlmb7//e8/jVcGAE8daiEAPIx6CADUQqx9/B12zwCXXnqptm/frrPPPlsLCwu69tprdffdd/PPwgM4plALAeBh1EMAoBZi7ePA7hngZS97ma6++mpdd911yrJMp512mj71qU/p53/+55/uSwOApwy1EAAeRj0EAGoh1j7+k1gAAAAAAABggMRP9wUAAAAAAAAA+Ccc2AEAAAAAAAADpPDfYXfCKcfZDdpdN8em5pAZL0f++WF3pGrG0w0Tbo6k1TPjpflFM14JfbePkOX2NRQ4K42jyM6RpG6OpFaxG2T+fxEd9e379SZRkiRuH2nq34sn5PaYR3GBMXfadDodM94tMDfkPNduL3NTzHfaZvxge8HN0Xee/XLuz41mxX5ud39nj5vjmablxHv2NJTkTgE5YUmS95cZFPnLDnJnquXekilwoa15ey7e98B+N8c99z5gxud23ePmWJybM+O9jv8Ok1PXvTKW1utuF0Pj28z4xs073RwbT9xqxrdv2eLmmGja19pL7QnW9yaXJK3a4bxt1zlJ6uX2cwslv+6n5YYZj2P/Heb97SLb1vs5nomSV11hN4gKFKLEfkbBK5hF2hR4/yv2cnjXUaAPb59b4F6fcB8PN3ri/bg9eM+ev5HnBwVvPIoMl7dvc95hkv/cggpscpz9ePj0u/wczzAv+dcvNePZwoybY5PKZrxb9j/bj5s8yYwfXjzo5lhM5834UDpsxrMZ/1uo52yWZ1fta5Ck0WH73Z0k9nhKUuKcTWQlf+HtOWjvQbdsss8mohX7bEOSyn372W/daO8dJWlpzt50tVv+t2Ncs5/twdUVMz68o+n2MeXs12cy/9uyVLXHdHh2xM2xaXzMjDeHxt0cf/etO834nV8p9q8Y8xN2AAAAAAAAwADhwA4AAAAAAAAYIBzYAQAAAAAAAAOEAzsAAAAAAABggHBgBwAAAAAAAAwQDuwAAAAAAACAAcKBHQAAAAAAADBASkUb5llmxscbDTdHNURmPM7962hWm2Y8L5AjjexzyiixhyXK/E6S1M6ROn1I/nUmBXKEJHFy2M9EkiInR8jtuVEqpW4fqTNemTP/JCl3bqXIeEXecDjXGUd+H9706fW7bo4o2HMjLrC0u72WGa+V/BwNZ02vRVmw43mB+uCOWoFhDc51hAK1MEnsebQ8v2LGv/XN290+vvm1b5jx+fu+6+aIZh8y4z359SFyxqvIn16lkV0L02CvmX7J/v2SNFW5w4zPNGpujruHhs14uuk4N8fOs19gxp9/zrlmfLTAnmCpY9eg0O+5OZzXpKL4if+5ZO684x5u4y04/9k/Izk1pEgtk7sPKTB23kQosNdxNwCxl6PAXHMnrJ+iQCdPRpInLLgbqkHhvByeKu5lFLjO2G4TFZijkdNPUIHNRVSgzRrTHK6b8Syz33eStDrXMeMrfX9c9+4/ZMa9ki1JccVu1Bi373VpftXtY119woyXU38PkaltxvOev4eYP3jYjPdi//2zaeN6Mz46XjbjUeTfa1i26+nywpKbwyshJecbV5KWVpfNeGO8YsYnN69z+5henrYbpP4k7mZ9Mx5l/r3u2TVlxrNk1s2xuH/BbVMEP2EHAAAAAAAADBAO7AAAAAAAAIABwoEdAAAAAAAAMEA4sAMAAAAAAAAGCAd2AAAAAAAAwADhwA4AAAAAAAAYIBzYAQAAAAAAAAOEAzsAAAAAAABggJSKNhxZN2bGy/3czRHaPTOeRqmbI3Zy5Jkdl6RSYt92EkdmPOT+OWfq9FGKEzdHvVwx45Vy2c2RO/cSBTeF4mA3yvK+GU8S/17T1H72/b7dhyRlWWbGywXGK47tZxtC1Yz3I3u8JSnLnWeiJTdHJ7fX26i/lJTW7fGIev6aHpI/pmuN94idKfSPOZwaU2BdepKSPxe/8917zPiXPvdFM37wjtvcPkrL+8143F11c/RK9jxLG3atlKSqs/4rJf91mDh1u5868QLvjtC127Ra/rpsHlox4/Ul+7lL0gP7dpvxe++43Yw/+4UXuX2cc9KJZrxIzc5l130VeK5xYo95VmB/kzs1ea0Kzl6nyB8LB6ceRpG/h3ALc4F3s5z9khsvcp2eItf5pPBeMkWuw8nxZDwT11M1Xh5nLJ6Ed3qhjUHutfFzhPAk1LKnbB4PjtbCjBnfMD7i5ghVu2BWOv7zq+UNM96o2N8xktRv23PACas8ZF+DJKWRfa+bKqNujkRdM16r+vNwuW3n6AS/rk/1DprxpRl7n7uxusHtoxvaZnz64JSbY+OmTWY8cfbaktRLm2a8vqluxvsdv76sH1pnxpc7/ndDUrX3JhuaW9wcB/YdMONbT9jo5mis99dCEfyEHQAAAAAAADBAOLADAAAAAAAABggHdgAAAAAAAMAA4cAOAAAAAAAAGCAc2AEAAAAAAAADhAM7AAAAAAAAYIBwYAcAAAAAAAAMkFLRhusmxs140m67ObLuvH0xsX85od2zc2RuCiXl3IxXSokZjxI7LklpbLeJg5tCSRSZ8VLsn7dGqX0diXOdkpR41+pcRgj+zZbLZTteseOS1O/ZcyMqMl6yxzyO7Xhwfv/Djew2Zee5S1KW2xPdi0tS4s3zlr1OJKncTd02a433dKIii1t2myj4czUE+xnf8JW/d3P87ef+2u5j171mPO4vuH3kjaoZH1k36uYYj+33y1C+6uaI1DHjccm+TklKnTaNxH6HRZWa20cntdt0nRokSYdze21PzS+6OUaXls342L33mfHvTU25fcyde64Zf9H5F7k5GvUhMx7irptDkb0e8+DXwlCgzVoUnDlf5JUob05HRd7ddhvntfuw5An+GXaB6/RTPAk5nPn8cCMnXiCFu7fz9kuFxsubGwUebJFn/0R5Y1FoW+A0ygrUmEL7D+863F1OkSRP/DqeYYaccVteXXJzVOsbzXi5549rLa2b8RD8b+1+295D7L/vgBnfUB91+9i6bcKOj9vnDpLUWpq3GwR/zEtj9nWEsr833LNij/mXbv22Ga+uX3H7SNv2nr/fsb+BJWlmetqMn3rmyW6OdTVnntfmzPhDD864fdT79rdls2OPtyRFzuFFteK/f9qL9nO5/5Zdbo50wt/3F8FP2AEAAAAAAAADhAM7AAAAAAAAYIBwYAcAAAAAAAAMEA7sAAAAAAAAgAHCgR0AAAAAAAAwQDiwAwAAAAAAAAYIB3YAAAAAAADAAOHADgAAAAAAABggpaINy6tdO1E/d3PkUWLG49g/P0wSO0e/0/JzlCt2PLaHpZKU3T7S2L7OJPLvtVxyHo/dhSQpSux+EicuSYnzaNNK6vThX2jI7U7yft/NUU7t6yh54ykphGDGk5JzL3nm9hE74xk3am6OTq9txlurq26Onr0MVCs13BytaX/drzXRk5HDSdKL/HG94Yt/b8b/4XOf9i9karcZ7pbt+TyxbsjtYms0b8YrPXvNSVKna8/F5bjq5ship24Hf74ncdOMLyV2vBzbNUqSqrn9rh0OK26ODZWeGe9tH3dz7LZLjGYO2dcxubDs9jF/iz2H/2/Lz/Gyl19sxkfr690cXWf/EnL//RMVqP1rUeQUsyj2K2bu7REK7A3llJGowJ5LiX2tXqWKnH3fP7Zywk/CG8a5j0LdhALv9syZ885zC5G/J/PmV3gSxuvJeKd74xU5e8uHc3hzw08ROXvp4G1AJcnLEYrUugL3u8aMbxo248sFvk+D85CbI/6eK6zYL+/VbsfNkTvvvO0T9h7i5LF1bh+Tkb3X6c7ud3N0W/a3Tnt1zs0ROT+71Ckw3bcef5wZf8GZLzTjh6fn/T62jpjx1VV/b1it2fc6NX3IzVGq2XW7JXueH7rHf67Zsj1Ha+v87+TVKXv/OD1+0M2x84ytZvzWv7rdzTH9XWczXRA/YQcAAAAAAAAMEA7sAAAAAAAAgAHCgR0AAAAAAAAwQDiwAwAAAAAAAAYIB3YAAAAAAADAAOHADgAAAAAAABggHNgBAAAAAAAAA6RUtGG82DLjIc/cHPW0bMbzyL+OPOs515G7OUIenAZeAq+BFMf2WWgU+TcbJXaOXP6YezeTB3+80jQ14+WyHU8Stwu1Wl0n3nFzjI4Om/E09cc8cZ6b91wTb25Jyvv2mJdHGm4OVewx7yz4Z/Hd7ooZb9ZH3ByNtOq2OeaEAvMssp/PV//2FjfH337+02a8cfAhN0cztefilgn7XsZ7bbePvG/nmIn9+T5TtudibpcPSVLInEKU+3M5cV6ZqVOTk9het5JUS+06NpyOuzmGYvt9vWlp0c3xvIb9vt59yjozftc+f26sm7fbtO/+tpvjxpL9XF/5skvdHFHJXgch77s5Qt9vsxZFwd6TlQtsU/rlITvuLxsp8vZ1fpLIqctR5MyTyN/sRM6GqMDrQ3L2jyH2t/ZeN7HzXCVJ3VWngf1M4qTAdT4J4xW8/XaB5ybn2yIO9kSPiuzXc3s8Qu7v6yK3Vvl1Kg92m6jAx1qRb7G15uD8YTM+UvH3On1nTXXrFTdHq3PI7iOuuTmqdknWzi1jZny07W/KlqZm7AbON7Ak9TKv7hf41nbWTNbx1+6eO75lxs96yRvM+DdW73H7GF8/asbrs/5zVWqP12Lb3jtK0sZq3Yz3l+29Yz0U+D4dtud5K7e/XyVpKG6a8cMPOPNP0uj2CTN+9vnPcnN89fP/4LYpgp+wAwAAAAAAAAYIB3YAAAAAAADAAOHADgAAAAAAABggHNgBAAAAAAAAA4QDOwAAAAAAAGCAcGAHAAAAAAAADBAO7AAAAAAAAIABwoEdAAAAAAAAMEBKRRtWlJjxEPk5osTOUa+U3RzdXte+jlLFzRFH9m3Hzr3GsR2XpODEs+C1kJLUvs5GtebmSEupGQ8FriPkdpuk5Ixn0nf7qNXt51ZK/edad3Kk5QLPzRmPPM/NeKnqX2fmLJbq8Libox7ZzzVpbXJzbMjse62Vm26OOKq6bdYab8Uksf/nIPc98JAZv+nTf+HmqBy2c/Sb9lyVpE1jdpvRFXttz6Yjbh8zuT2Pet2Om6MWlsx45NRKSUrL9lxNS/54xYn9/olLdq3rx/51dnt2fZju+HVstbrOjM+N+zVmS2fajJ+4Yj+3Dcf7c+PLB+0ck1Orbo7ebbvN+N9U/tbN8ZMXnWc3yPx3WCjQZi2Ky/a+rbcw6+ZIa3aOqOzvdfqx/U6U/HezJ4q96l9kI+y0iQvkSOx3TJz7NSIOdr1LnL2OJGXO3jCuONfhxSVl3p6rwPvWG9O+820iSbnzXZC5Y+4/1yh32mRuCjdHFPzxinO7TZ77FxI5c2MtmrtvwYz36/5eZ2jSnu/LHT9H6LfM+Gruv6t2rrf3CMM9ew605u2xkKSsb+eo1fy6Pz5s7zNWl+29oyT1u20zXi77a3f/oXkz3po9ZMY3jNbdPmbnDpjxsS3+vm734SkzPt60946SNDIyasaXV+17bY4NuX30I7t+zOYrbo5y2V5LO8JmN8eer+2x+xj26+mWHRNumyL4CTsAAAAAAABggHBgBwAAAAAAAAwQDuwAAAAAAACAAcKBHQAAAAAAADBAOLADAAAAAAAABggHdgAAAAAAAMAA4cAOAAAAAAAAGCClog2TOLIbRImbI47t88FyOXVzlEp2P14fD+ew+4mV278/KdKHPbQhBD9HaueoVqpujnK5bMb7/b6bQ861JnLiBeZGVLGfSVDm5khSZ/44z0SS8uDM0Vrd7qLRcPtIyxW7QeLEJfUzez02G/54DSf2eOVZgfP8ULiErBlOJdRKu+fm+Pz/90Uz3t6/182RpKtm/OQRe+1LUrVVM+PTFTu+0PHnyEh/xYxnScfNsVKx+0lrBd4dFXs80rjAO8yJt1K7RT/vun2U+ktmvBH79SHvt81454A/Xvs3n2DGS/1lM37y7Izbx8Xb7Wfy5bzl5jh+wZ4/e75zs5vju5uHzPhpJ5zo5shyv+auRdHQiBkPHXs+S1Jv8bAZT9L1bo6kab+b8wLv1cjbP7btmqvY3jtKUnD2dZG315YUOZcZ+v47KM/tfVsocC+q2es3OPu6LPb3n3nbXt+h7++lI9m1PfL2ZJJKZXu/HVJnLAp8bgXn2yMEf7xCbvcT9/13dpw578JC11Fg/qwxJ295lhlfXfVrYRzZa3eoQH1Iqva+7cCcvSeTpC01e76Xl+0ceYFvy9j7Zov8e61U7LWb9fw9V8jsMe93/XraHBo141MP3mPGj3/Ws90+Htg/ZcbHxifcHIcPzprxUu6PebNp9zM8Zo9X5JdbrczYz215ac7N0a3b7+uJDf54pQ/Y4zG3234mkrRh/aTbpgh+wg4AAAAAAAAYIBzYAQAAAAAAAAOEAzsAAAAAAABggHBgBwAAAAAAAAwQDuwAAAAAAACAAcKBHQAAAAAAADBAOLADAAAAAAAABkipaMM0Scx4UorcHEnJPh9MogI5nOtoNptujii2ryPvd814tZy6fYQ8mPE09XOUvOvMczeH1yYp+VMgda6jJPtek3LZ7SMqV+0G5b6bI0+cMa/7c6PWGDHjUWpf52ovc/tQsMc85PYcl6SoZI9pIn9ueKutyBxVOPbO/L0Vc/t37nVz7LrtDjPeCD03x8Q6e75Xso6bYzraYMZXWitmfMip6ZLUq9prIq36NWj7kD0XG/1lN0doz5vxqGOPpyRF3rKq2OFSfdjto1MeM+OH5dRKSb2oZsY35v67dvqwXXMfWLfJjJeittvHtgP7zfjZW+16LEn3te1+ju/4c/SOb37bjG+YmHBz1Ov+c1mLslrdjMeT690c/UO77T4W590ccWLP+WjYWZySotheF3nHrocq+e/uuGzPR78KSSE467fAq9srAVHiJ4mcjrLcrv0hK7BfcsY07xfI0bffp9GSveeXpChu2XFnb5hWG34fVXs8u85eXJJyZ27ksT9H5QxpiArkKPB9stZEDXsObJyw3+2StBzsvUzSXnVzDNXsuZam/nt1KLLnWndlyYyHAoWsUrFr9sioP15l5/uy45wZSFLi1Jg48vfjdef7cubwPjN+qOq/n3aeeroZTwp8jy2PLZjxlbq/NzxcmTHjs0PzZrw56r9bTj/pXDMevuPXl91Dd5rx6a59H5KUDtvfJ6P9cTdHrebP4yKOva9tAAAAAAAAYIBxYAcAAAAAAAAMEA7sAAAAAAAAgAHCgR0AAAAAAAAwQDiwAwAAAAAAAAYIB3YAAAAAAADAAOHADgAAAAAAABggHNgBAAAAAAAAA6RUtGE5tZuWUv/sr1xOzXiSJG6OPA9mvFKuuDkkO0c/z8x4tVJ2e8j6do5Gs+7mcC5TceKPuTemWWZf5z8mceL23MiSqt9HuWGGK0P+c02SyO6iavfxj43McLvnzZ2+20XsLLs08edXpVwz4yFyJo+kTrdjxpOSfx1p6rdZa1Z6PTP+D393q5sj9A+Z8WjMfjaStLNv19PD8YibY1b2vUzE9toPcdftozFh97E+2OtWksoH7fGYd2q2JPVyu58s8+tpFNltmi379yeLTgNJw3V7TNc3/eucrY+b8Ydy//0zmi2a8cNz9nO9u77T7aPasfs4ZWbGzTG1dcKMr3zHH6+J1O7n3gfvcnOcc+qz3TZrUV5x3s2VdW6ONLPnfH/Onwehs2LG87a/v1TJ2efWnHiBd6azhVUW/Hd3cDaHoUA9lHI7R8+vy+6VOjcbRf4ziSL7PRec7wpJUurca4H3WOja9U4tu7aH1qzbR1Jr2vGRMTeHavZ6DCX/ucrZ5xb6WY9gj/lalI3aY/udu+92c6zbut2Mjw/5+7qlVtuM12r+t5D3bbiyYr+7y85clvxv2JHhYTdHvWnfS9b313a/Z+8vqwU+YVcze76PNe1vttX5abePkclNZrze99f2of17zPhSxX6uknT36m4zvqwFM95s+XX/2ac9z4xvH9rh5tg9810zvvyQvU4kqSx7Dm7eeaKbY2h0o9umCH7CDgAAAAAAABggHNgBAAAAAAAAA4QDOwAAAAAAAGCAcGAHAAAAAAAADBAO7AAAAAAAAIABwoEdAAAAAAAAMEA4sAMAAAAAAAAGSKlow7SUmPGk5J/91WtVO0fiX04U2f2UEvs6JSmO7RzlxI5XyqnbR6lhtymnfo7Yu5co8nM441Wp+DlWVlbM+HKwc6TDw24fiu25UakPuSnqZTvHSq/v5igF+7nEFXuO1vzHqqxvX0cIfo5y6qyVAmup08/NeNeJS1KpfOyd+e89OGfH77nbzVGN7TW1terXsZ7KZnyla8claVT2ZGs12mZ8Q9V//htXu2Z8eanj5tgT7BpyOK+4ObpOnerFfi2MSvYCr6b2dYyU/WeyMeqZ8cnZA26Ord19Zrw2dKKb4wFnfq3vZ2Z8cXHR7ePg8fZ1bOzd7+Y4a9R+N9w0bs8/SdrQXTXjc3v8MV/Z5o/pWhQl9poIJX9tRuu2mvE4899FctZvHhfYXzrrO3Tsd3eW+/UwOPvLPLPXvySFnt3Gr2R+o1BkI+Ik8eaGvH2MpETOvq3AZWaR/T4NFX+Oquy8k/v2M8n7/nsudO020dKymyNq1O0G1ZqbQ127tsd9v6aGvMCaXWMq2+2xX9+fcHPEVXtCT++131WSNFq134nl1J8DWWY/465TpmpNv49SyW4zMz3t5mh37b10lPo1OXK+l0JsrwdJ6rXttduP7frR7vhrKnZq8tC4/629OHPIjB/6zh43R79uj0e9ao9FqUDN3l39lhmfG/LXQbXfMONLqT/mIzvsMS31Crw7nG/+oo69r20AAAAAAABggHFgBwAAAAAAAAwQDuwAAAAAAACAAcKBHQAAAAAAADBAOLADAAAAAAAABggHdgAAAAAAAMAA4cAOAAAAAAAAGCAc2AEAAAAAAAADpFS0Ya1WNeNpOXFzVCplM97r9QtcR92MR1Hk5ohj+5yyXrHvtZL6fdRqNaeFn6OfZWa8XLWvU5JCcK7CGQtJavV6ZjzzplHqX2ee2G3aPedGJOWJfR0hLzDmfXs8Umd+pam/Dso1+zq7nY6bo5V1zXipwFl8u2U/1wJLSc3msXfmv2vPPjPeXTzo5phIK2Z8vbdwJc2WUjOeBHuOSFJUsmtutWLPxYmuP1eXF+26vzefcHPsjuzxqJfsWilJiVNzs74/5nHI7QbOopmN7LGQpBU1zXireaKbI1s5YMY3x3ZcknrrNpnx2dAw49tro24f/ZHNZnyltsHNcdzc/WZ87Hh/X7H4XXse16ac5y7pwPSs22ZN6trjG0r2nk2S8tqwGY9G/BoRJfa7KBla7+ZIynaO7tR+O0FtxO2jNDZkN+iuujnyw9NmPC4XGPOq/Q6SU3MlSZm9LqLg7Q/8tan5Q04Kv/arbNeqyPm+kaQo9fb0trjAfirKnEaJ//6InO+Xfurn8Lb0cdtPkTvfDWvR0iH7PXLS8ae7OXpRy4zvmb3XzTF1yH6A+xedNSVp7Ez73Rs5ayrE9j5GkkYmdpjxbnfJzbG8bLdJq/58j511VXJKpSSlfbuWLS7bdX2l7e+le863YbnsH+lUSnabascvVOsqo2a8LvvdMT5mv+8laahtf0tPH/DfkzP77TbVHf57slO3cxx4aMrNUV2ZcdsUcex9bQMAAAAAAAADjAM7AAAAAAAAYIBwYAcAAAAAAAAMEA7sAAAAAAAAgAHCgR0AAAAAAAAwQDiwAwAAAAAAAAYIB3YAAAAAAADAACkVbdiolc14mvqpyuXUbhBC0ct5QtdRSRMz3qjaORr1ittHteK0yTM3R6ttj0dS8u+1l9htSkPDbo7GyIQZb1ZGzPiBqXm3j2qpasa7XX+8uqFvNwiRnyO3c2TO3ImqzjVIimv2c+1lPTdHe9mZG4l/Ft91ukkSf7zaHf9+15qpAwfNeKnfdnMMNXMzXonseSZJ3a69ttMic6DeMeM7nHXXXvXn6r0lu36s5CtujrHqqBlfXVh0c8Sp3c9Q2X//xJn9XDodO0ee+eul5tzrvmDXSknqTZ5ixpPFu9wcJzjPZejEHWa8On6G28fSij2/Vsr+OuiV5834qUM1N8dXSqtmfKRl9yFJh/bPuW3WJOd9lUQF1lWw62Hm7GMkKR629yGh6e91MqdkljZuMeP9RtPvo+bsg+XniEdGzXiSeH1IKtlrK5P9TCRJuf1sy065Sxdm3S6Wppx3TOrXw2TDJjMeN+tuDu9tGjpdM5617XetJOXBzlFgW6DEeW5lZ61JUt6zH1y/499LSApc7BrTO2S/Rw6s7HdzrPRmzHht2N+Xp85s3btkX6ckTbftdbd92077GkLD7aMxZtfTUoH3bnvJrnWdvr2mJCl2Fnel6s/lTs/ey9Qadnyx7V9n1rdzeHHJP5vYtsV+JpK0YWzUjA/V7fFKC3xb9nt2nTq+NOTmyDedZ8b/4aF73Bwz+WEzvqNxgpujVHriZ1sSP2EHAAAAAAAADBQO7AAAAAAAAIABwoEdAAAAAAAAMEA4sAMAAAAAAAAGCAd2AAAAAAAAwADhwA4AAAAAAAAYIBzYAQAAAAAAAAOEAzsAAAAAAABggJSKNhxq1O0GUeTmSJLETpH4l5OU7DbNWtXNUU7say2VUzOexxW3j35iX0eIg5ujNDJuxjtR2c2x2rf7aTY2uDmS2H5u3W7fjE+s98dreWnFjI9Ua24O7/h5cWnJTdFu9ewuInssqqn/TGpD9twoVew+JKnsdDMzO+vmWG51zfjQkLPmJcWlY+/Mf2l20YyXcn9tV0v22PejITdHL7PrVCmx57IkjZYzM5607eucyUfdPubj3IyPNfz6sDr3kBk/YdLPMVmxryPt2zVIkhTsd0fXqfu7O/Z4S9LC4kEzXh0+zs0x5czBdUMnuDk2rtr18qxtW8x4+6TT3D5mHjxsxw/YcUnqbt9pxrct7nNzpDV7zPs9/92xMjvvtlmbnBri7NkkKfQ7drzi7+uyxrAZz1O7XkqSnL1OXLVfvFnqv7uVOuMRF3inlu06ZFe6hwXZNSLkBbI41xo69nPtrSy7XZTG1pnxZJNdhyQpG5sw40XGS327VZbZNSIu8G2iij1eWb/lpsg7bTNeatt9SFLedvYOIyNuDhVY92vNSMWuMSG2v5Uk/1tofs6fA8dtsefq5Ga/xtz+/V1m/LyfvdSMzzzgv7t3PWD30az711kvO3u/kv/t2FmdM+O1qv/uqOV2Te448WTB32OUnDOSftfer0tSuWTfS7XAuzZ1zkiyYO8Jus63pyRlfbuO1VL/+2Zj2T7f2BI2uzki2e+fydjed0jSbHfGbVPEsfe1DQAAAAAAAAwwDuwAAAAAAACAAcKBHQAAAAAAADBAOLADAAAAAAAABggHdgAAAAAAAMAA4cAOAAAAAAAAGCAc2AEAAAAAAAADpFS0YXOoacbj2D/7K6WpGe/1MzdHHAUzPlQv+9cRR2a8FezrjJoTbh/dxL6O5VbXzREnDTMeKkNujuWVlhlvL7op1Biu2w3ith3PO24fqfNcQ8++D0nq5H37MjL/OioVex6HYM/RpdUVt4/p+WUzPjxqP3dJGh6253Avd56JpDix53mQ/UwkaW5u3m2z1rRX7bmYxLmbwymFauX285Wk4P15S+rX02FnTXizaC7U3D7qVTveWvVr4cnrK2Z8fZhxcyRT9njEfX++h8SuMaOxPTeak5vdPh6oj5jxQ4en3Rzlqj1ec5VxN8diyx6vNLfvdTGsun0sLNgvoDjx10FreNiMN+79uptjpGrfa69dYG607bq+VsUT9lwKFacASFLk7LkS+xlLUl61a1EoOUVXkhJ7S5w5JTdx9paSpCgxwyH4OSInh5z9lCTFwdlzyX+PRbF9HVls18vS+g1uH9W6vR/qOrVOkvqJ8+By//sld8Y0GbPnV+I9M0ly3sdR8PewoW+PeX9+3s2RDtvfFvnYqJsjK/A9t9aMjtq1cL7fc3Os27DNjB/Y8z03x/7dB8z4yTtPdHO0OvvM+J45e891wqb1bh+zD+0x452W/90nbw+a2GcXktTp2bWuOeTvc6t1u4ZEzndDxXl/SVLfWdvzc3NujtR5xw01/O/PuGTfa9+Z552OX8ei3M7RdK5BkuZ79p4sCv56HBvfaMbrRfY3KrAvKICfsAMAAAAAAAAGCAd2AAAAAAAAwADhwA4AAAAAAAAYIBzYAQAAAAAAAAOEAzsAAAAAAABggHBgBwAAAAAAAAwQDuwAAAAAAACAAcKBHQAAAAAAADBASkUbDo80zXgIfo4kScx4nPiXE+U9M14pcEdxqWzGO3nVjOfVUbePnux77fT7bo7MyVFLUjdHlNjjtbK45OaolStmPKna577z8wtuH1G/Y8dL/oOdmpo34+2O3YckrVs3acbrjZoZr9XdLnT4sD0ei3OLbo44stdjmtrPTJLKqT2/Vlf8ubGyvOK2WWtClpnxKPfXdim222SZn6Mqu+jm5dzNUXPq9mxuz6N2ye+jHOz6kFb8HJtKbTM+HDa6OaYnNpvx3dP+mHeW5834+sRe21sTf72cuMl+Py00/VoYd2bM+Ep5xM0xXbavo7s4ZccPHHL76IVlO574G4uVw/Y7rj6/x81Rq9iFe6XABifp+e+XNcl5Z2b9yE0RvOdsv6okSVFi15ko8a8jd/qJYnvPFWVdtw+nbEsF9nUhdv6sPfJrqjr2tcZZgU19al9HVrP30lnNr9uZcyt9+XVbkX0vkT81FDnfL8GJ9wsMZ0jt8QqRXZMlf/8Re3NHkjd7MudeJSkU+ShcY5zPU00/NO3mSJz95VjF39srDJvh5Rm/Ppy98zQzPj5kf4N0lux3uyTFzvdpLzgDKqnrLP+kwDFHL7MLwEK7wF66avfjfX+W6/Z4StLC/LwZX+z4+8u+822RFDiHCT37uXRWVs14kW/LNLbHfCi157gkDVftejo07o/5zMq8Ge/2/JpcKvB+KYKfsAMAAAAAAAAGCAd2AAAAAAAAwADhwA4AAAAAAAAYIBzYAQAAAAAAAAOEAzsAAAAAAABggHBgBwAAAAAAAAwQDuwAAAAAAACAAVIq2rBSqZjxOI7cHP1+ZsZrdbsPSSpFqRlPClxHK5TNeFDTjqd1tw8pMaNplLsZ+u2WGe+2l9wcaRTM+GrHz9Fetsd0cXrZjM9MHXb72LxunRlf7bXdHPMzC2a8Wm+4OVaWVsx4a3XV7qPpn4FPjNrzLw41N8eevdNmvFTy59fkxJAZr/hLSb0C83itqaX22s5krzlJSjK7TSS7VkpSGuwcHXUL5LDjWXDqbcm/12aw50i92XdzDHXsGjO9aNdsSfrrRbuG7F+116Uk9ZbstTme2df5huPdLjS+NGvGJ9dtdXPMHbTrmCJ/frVTu5YdfuA+Mz46+Wy3j+aI/S7dv9t/d8zO23V/su+/45Kkasb7wV7zkpR17HfDWpXFztgkfo2IvH1b4r9XI6dJKLA3jBK7BiT9nt3Hsj0XJSkecvYhPX9thpKzVy778zX0OmY8Cv54BecTwkvRK/IzA7HdJpJ/nbFT74I3eSQF5z2Wd+z3S5T7e6XIe64l/5MtlOw5nDcKrIPcXrNF1lKBx7LmlCL7+Tx757PcHElm51jtHHBz9Ev24G9q2t9bkjQW7DWxvHevGZ+ZdfYgkoaH7fd/8N4tklrOuos7fj3tZPa6y9t+jn7fvo5l59ty444T3T5mpqfMeKPIu9ZZmB3n3EGSFpfs91xnedGMxwW+kVRx5l/bn1/14Q1mfGjIv46p2T1mfK5r7wkkKfbqekH8hB0AAAAAAAAwQDiwAwAAAAAAAAYIB3YAAAAAAADAAOHADgAAAAAAABggHNgBAAAAAAAAA4QDOwAAAAAAAGCAcGAHAAAAAAAADJBS0Yblst00jv2zv3K57OTwr6MUR2Y8KlXcHHk8ZMa7/aoZX5xbdPuI4sSM1+t1N0etkjp9uCnUXl0x42nNfiYPd5SZ4UoSzPjG9evcLiple8zbna6b44Sd2814lvXdHGnZHtQ8t8fivvv3un2MDNnPddOGETeHsmUz3G513BRz/XkzvrTUcnO0Wv5zWWuaw/ba7cpe+5JUcoYtL+Vujn5kt2lU/FpY6iyZ8bLseRSXmm4fabZqX0PJn6uVzL6XB6f9HLc8NGPGk5L9bpGkkNn1YTmyr/Pwsr1uJWlTz64xI2X/OucSr40/v8ppw86waI9nf2W/20erbde67kOzbo7ZYF9HCP56DLndJo/9rVKW2c9tzQr2+18qMi72fA2y35mSJGdvKGdPJklRbucoL8zZv79j1zpJyjK7VvXm7D2bJJXXb7ZzjNp7XEkKznOLC8znvtMmRM6YR97cKdDG60OSgrNZ9kuqgvd+yOzriNo9t4+o3bavIfXf6VHV3tOHkr3XlqTgvB+i3N9LB+e7YC2qNOzns3ev/31w2ilnmvG467+L7vr+HWZ8S8OvD/d/57tmvLts16ktm45z+/A+yToFvtk6q/aeKmT+POzk9poppf77J03sWhhHdo5m1T8T2PvALjM+tvM4N0cI9nV2W3YNkqTYGdKsaz+3foH6ETn1tF/gmXSdubGwMOXmKFXsup02/TOUlQLf0kXwE3YAAAAAAADAAOHADgAAAAAAABggHNgBAAAAAAAAA4QDOwAAAAAAAGCAcGAHAAAAAAAADBAO7AAAAAAAAIABwoEdAAAAAAAAMEA4sAMAAAAAAAAGSKlow0o5NeMh8VOVqxUzHvf7bo442PGl3L+OFdnXEdKqGe/0Vt0+RkZqZnxsfNTNUa7YY760vOjm6HbaZrzWaLg54jiy43nHjOcd/7kuLdtjWqmU3RwTo8NmvFRN3BzTs4ftBi17PMt55vaxeHjObrA65eZoLfbsBpl/HQ/tnTHjva6fY3h41G2z1oxu2GjG89iuH5LUz3IzXq06z1dSo1k347WaXYMkKfTmzXglttduHvtzpOXEK7k/Xsn6CTO+OR9zc5yR2Nd6//6Dbo5OZP8Z10hi1+xqsuT2obhrx3P/z9lSp9T1C9Spbs++l5IzN/bfd6vbx945ew535vx73Txi32wc/Lrfy+13XCR/vPqJ/45ak0r22KnA+IfYec4ley5KUu7sU6LEuU5JScveh+SHdpvxmnMNkrTaWjHj8XKBfbDzZ+25s3eUpDi12/Ra/v4yNOz1q8h59rmzoZcUyX5Xuh8FkoJTt6Pc6ePhC7HV7O+KqOo/k6jvzOF+gXt1934FxjxxxstPIe+xrUVJau/bFled7wtJt37nZjN+3Knb3BzVEfs6Dh3a4+ZYOmR/h2yZnDTjpcSv+31nrvbazl5IUrXsfM8XWNutZbuf5bb/zd9o2Pvt5si4Ge91/T1/FOx7KaX+HiTv2+PVbPpnAq2e/Y7qVe33wuKC8w0sSc69Bvnzy9sIL3ftd7EkRYld7PrBf1/n8p9tEfyEHQAAAAAAADBAOLADAAAAAAAABggHdgAAAAAAAMAA4cAOAAAAAAAAGCAc2AEAAAAAAAADhAM7AAAAAAAAYIBwYAcAAAAAAAAMkFLRhrVq2YyHJHFzVL0c/YqbY3a5Z8bnc7sPSeokdTPeHB434+smN/t9dFtmPEr8s9J6w77OlaU5N0fW65rxasXuQ5KyPLNz1BpmvB/Z1yBJWWI/15WVFTfHoY6dY+NxW90cuex5fO/3vmfG09y+BklamZ81462Z4OaoplUzPjk56uY47bhTzPjGjZvcHMMjw26btWbT9m1mPGmuc3Ms9KbM+OamX8dm0sjuY27ZzdGspWa8kbbNeK3XcfuIqnYfS0v+mnmoatfTHXV/zbz6hAkz/nfxpJvj3oOLZvzsMbvWjY303T5WGjUzvrBo12NJComdQ1Hu5qi35u0G6ZIZnnF+uyTlc0073vPfT/XYvtc82OtEklpde/5EwZ+jeTrmtlmTys42MvhrM4qd/ZAXlyTvMUf+PEgyu571Fw6a8RVn3ydJ/dVVM56WR9wcpZ5d2+OeXbclqVyx99t5217fkhQ567NXct5juT834tV5M15y9smS1HNqQOj79TA48zyU7L1j5uwtJSmJ7Hkel/w5HDL7/ZBn/r2q77xjCqxpFWiy1hx6yN7X1cv2t5IkLazaOR586C43RxzsuRrH/h51eHjUjK+07L1Oue/vdVJnPlfK/ppp1u1vodVlv44lzn6o2/Pr+rqhDWZ8+86TzfjePQ+6fXhnKEmBc5hKw95zdfv+uyOt2u+OuGo/k/aMPzcyp360+v65QqVmX8fw+o1ujuGKt2b9erpr5T63TRH8hB0AAAAAAAAwQDiwAwAAAAAAAAYIB3YAAAAAAADAAOHADgAAAAAAABggHNgBAAAAAAAAA4QDOwAAAAAAAGCAcGAHAAAAAAAADBAO7AAAAAAAAIABUirasFqvmPF+p+fmiHt2m+le2c1xqGtfcl5pujn6cd2Md4N9Hf127vaxvLBsxocaVTfH1OqKGV+cX3RzhL59rWk9dXPk/cyMD1ft8WqHjtvHgblZMz43s+rmiMs1M14b67s5hmoTZny4bt/r+hF//m197hlmfHJinZujVravo+I8E0mqN+zxKjt9SFKcJG6btWb7tg1mfHT9VjfH4r6HzHjWs+uHJHU6M3Z81X820yW7Jm9L7Ph4N3L7mO3bfy5Ujux6LEl7Fg/bOeLdbo7mkn0vP1H3r+N5W4MZn6zYfaQF6sO+1F7/czP+u7Y8utmMh8i+D0ka69ljrlLbDC9mQ24fSc+eo4lT0yUpiezx6Jb8Obq8YOdoRPY7UJLKI8Num7Uoirw/9/X3S94TCrk/5+XN6djf68SRfSVR6JrxbnvO7SPJ7PGIg783zHr2fqjc9fdL2b4HzXh+0H5HSZLmps1wtP1kOx4X2D/MHTLDScuvEZ1lew+a1/26HK139mXB+ZzK/ToUnJXgV21J3hx2V5uUZ069C/6aVl6gzRqzdb093x98aJebY/vGcTN+977b3Bylsl2Th0p+LTz7pOPN+L499v5gxfnel6QR5zorJf9nitotu9a1O/73Z5LadWh8ctLNcdrZZ5vxmUX7e35mzn93lFN7PELsH+mEvv0O6/f87+RObteH4OwJJjf730irbfsbaKnrz69+x76XSoHzoq2b7XVQ9reGitr+mBbBT9gBAAAAAAAAA4QDOwAAAAAAAGCAcGAHAAAAAAAADBAO7AAAAAAAAIABwoEdAAAAAAAAMEA4sAMAAAAAAAAGCAd2AAAAAAAAwAApFW2YllMz3lfdzbHr8KoZP9DpuTlKQ6NmvF4bcXOkUdmMz87Mm/Gs23H7GG3afVQKHJXOTc+Y8eWFOTdHr9c3452W/Uwkqb2yYsb3r9rXsZotu310epEZP+XE57g5yiOjTouKm0OdRTP84uefa8ZP3D7udlGrVM14WiqwLEMww+2uv5Z6WWY3iJy4pPgYPPKfHK6Z8RNOOd3N8e09d5vx6f68myMN9lythlE3R6tj1/V2vW3GJzM7LkkLbXs+l+r2epCkfr9hxneV/Ym4fsyuY0NDdlySSrm97rKyPTemkgm3j13T9rujXh9zc7R6uRmfTOz3giQNBbuuL6T2vXY7fh/BqWOV+pCbY6xznxnfW7PHU5JCy76OXpy4OUY2+de6FkXOmpAXlxRy+10TxfZ8lqTgtYn8Zxj6zjuvZ79XowJ7w9jZdmcr/p4sa7Xs6zi0383Rv89+B0WL024OLS2Y4VJz1Iwnk+vdLrrzU2Z8dZ8/XlHZ/i5Ix/19WxbZe1T17fkX5wXmX2SvlTzy14G7HsMTzxFyP4eKtFljmiP2XmZL3/8+XVq05/NY088xut7eL81/3947StL+kv3+P+k8+1to9qD9/SpJncV5M97N/HqalO16OrLxeDdHfWzSjE9u2ujm6AV7v3PXXbeY8azj3+vwiF0vR9dtdnO0D+w243Hi16lqc9iMl51v7VxOLZWUjNj73LmZA26O0dhej3O7HnBzHIrts62tI/bckaS0699vEcfg5zYAAAAAAAAwuDiwAwAAAAAAAAYIB3YAAAAAAADAAOHADgAAAAAAABggHNgBAAAAAAAAA4QDOwAAAAAAAGCAcGAHAAAAAAAADBAO7AAAAAAAAIABUiraMCmlZnx63s9xOIyb8fJo1c3RqCVmPAq5myMKHTNeC20zHqd+H92Fw2b84OElN4fUdzqxr1OSlmZnzHiv33VzVEr2mI/U7OcW5yNuH42kYV9Dre7miJ3j56W5KTdHtDprxsc2rTfjjaq9TiQpBPu59vvOc5cUOTeblAqcxceRnSPxc0SRnWMtyhTM+Gnnnu7muO3vbjLjc6vTbo6NDXvtNip+fejGTfs6nFfEhrJfx07o2NdxX3fSzVEZGjbjca/m5pjqVMz4oWjCzdGVXYdafXtulP1yq+HU7mOp578n6/ataufqvW6ORsWuZQ96db1ddvtYqtjP9dTSsptjojtnxm9pr3Nz1CL7uS1U/RzP3uy3WYuiTs+MZwXeRXFu54hC5uYIwd6nlHJ/8eUH95jx/py9r1Nn0e0jc2pE7NRkSSp17L10b6+975OkaNleN0Xe7WHJ7ieZ3mvGy6NDfh9tuwZkc/aeTZLyur2nSnpb3BySfa092eOVR/53g/szFHmBZ5Lb9xpl/lqKnTYh9+8lL7Bm15rv3fltM37iTn+etZbtPdX68TE3RzOx36vTy36d+n/f/TszHjfs991zzzzX7WN11t7nLiwtuDmaExvM+IZN29wcUWrvqVotf7y++fdfNePf+vbtZvy4DfZ9SNKm7dvNeLnibPwkLXbt849ux39PpnV7ftUm7VrZcb4JJGlh/z67Qd/fVwTn3Grb1q1ujsUZ+52/UPGvY67APC6Cn7ADAAAAAAAABggHdgAAAAAAAMAA4cAOAAAAAAAAGCAc2AEAAAAAAAADhAM7AAAAAAAAYIBwYAcAAAAAAAAMEA7sAAAAAAAAgAFSKtowBPtsb2luys3R6Qyb8XVDVTdHtLpgxuOQuTnyfteMrx46aMbr1Yrbx+S4fa8jG9a5Oep1u58oitwcq61lM57lfTdHo1Y240lkx2/+1m63j8VeYsanZqfdHM2GfR15a9bNcfzGITO+Yd2InSD3n0mpZC+7qGSPhST1Qm438JeBEvnX6smz8IRzPNP0gn3PO0/Z6uY46bznmPE9N8+4OcZq9toeGfYnQTfYdWopsufqwVLP7WNjbNeYU1cOuTnum58w48ulmpujVLHrg0r+XI6dZTeW2X104obbx2Lf7mSktOLmOLFttxkvL7o57qlvNOPT3VEznrb8+jI5Yb/zt3T3ujkeqtlzdP6Am0I1588uyxsm3Rxbhvw5uBbF7VUzntfrbg6npCoUelfZ8yBe9ud878ADZjzp2uuqtNp2+4i6ds3Mgp8jy+waEdftfYwkldfZ61upvx/veGPasu+lt+s+t4/+tL0fjwuMeda330H5vofcHKkzpt6Y5/LfL1FuP9fIef9IUnByeHFJCt6CLJBD3h51DaqX7XdAr+2PSbtl15hqM/UvZNn+hmg0/PowsXm7Gf/M579gxnc/uM/t47STTzDjo2Njbo64ao/59Lz/7fjQXvta7/red90c373bbjPUtN+DHaemS1Ivs+vY6qr9TSBJq878kgrUB6eerjgfoN32kt+Hc50TE877S9Lug/a3xejmDW6OPLP3N9+7/ztujslh/1qL4CfsAAAAAAAAgAHCgR0AAAAAAAAwQDiwAwAAAAAAAAYIB3YAAAAAAADAAOHADgAAAAAAABggHNgBAAAAAAAAA4QDOwAAAAAAAGCAlIo2rKQVM76+4edorRw0491DC26ObmfVjG/euM7NsWnLhBk/Y/uIGW/Uqm4f9UbdjCelxM0RRZEZDwpujji27zXLugVy5Gb8nvsPmPGpqWW3jywdMuNDDXssJOm4zfa9bp7Y4OZYP5qa8bLsuIJ/Bt7PMzMehQJzI3GWrj81lJbsHJlznZLU7nT8jtaYamQ/n578cTv3BRea8btv+b6bY9fSXWb8jAJ1amSoZsbjjn2vSx1/vi80V8z4sKbcHKe05s34/l7LzbG4Yt9LX/ZYSFISnPUf2euhXPLr7abYnj/blufcHOW6XS+/X5l0cxzqNc14aNtFJm7a9ViSTg72uyNJ226ObyzZ/Yz0/PW4p2xvYF54oj0WkhSFnttmLSq789F/GeVVe/yzAjnSvv2c8zl7/ylJwakzpb69fpNlf77GbbtNOfHf/73MvteQ+lv7bsve05cSew8rSaX6mBnPnPGIlufdPnrTh814Gvy9YVy134VRgRxh1X72Uc3L4feR5n0zHnftuCRlzlLxM0i5c61RKLDBzAu0WWPi2F5Th6aX3BzVqr3uKvbnmCSpPGbvZTZVxt0cO3ScGe91v2HGb/ibL7l9fPuO28z41i0b3RxDQ/b3epL6627/ob1mfN+BGTfHxi077Ouo2HvH5a6/N8yd9+DsnH+dS4v2OUs18fdLWW5/0/czey/UadnfBJKU1u2aveGEk9wch5znenDK3xOcdLL9XB888JB/HVPTbpsi+Ak7AAAAAAAAYIBwYAcAAAAAAAAMEA7sAAAAAAAAgAHCgR0AAAAAAAAwQDiwAwAAAAAAAAYIB3YAAAAAAADAAOHADgAAAAAAABggHNgBAAAAAAAAA6RUuGHFbrrt+G1ujvFNPTOeK3JzVCtVM94cbro5KlU7R6xgxhO3BykPdo5ezx4LSQpOjpBnbo44tnNIuX8dJftct5vbOTaM+NOs1iib8dNP3+7mOH7buBkvl/zxClnXbhCnTgL/DDzvdsx4VmBuqG+Hq+WGn8OZyQVuRZFTF9ai1qodP3S45eaopiNm/IUv/Wk3x1e+eNCM11dX3BynlJfN+FipZidYtNetJC0703m+6tf9daV9Zvy45cNujl5mT+iQ+feSBOfdEdvrIYmdhSsplO3xmGkOuzkOJM6Ytuz5J0nVntNmyK6F26p+HaslM2b82wWKUJix26xU3BTafOJ6M75p3J+jrd6i39Ea1L7vO2Y8jG90cySbjzfjpeaQmyMszprx/qHdbo6ou2THg73XibIi7+62GQ4FtuUht+djb+YhN0ceTdl9DM25OUpVe58RtZ13YbD3QpIUd5zxKrJRcZ5LbcM6N0WvYdf+frD7SCJvLy5F83Y9zA/bcUmK6vZaKU0UuNfEeVf6tyI53wVr0a7dB8x4XPbX9rYt9nu3O7Pg5hjfau9l+iU/R23Fvo5TTzrFjIeuP0kOH9prxu+59wE3x2rPnmflEX9ft3XnJjN+5o7z3Bwj9TEz3nE+HELLrnOSlDjf4r2un2P9hkkzPnNwj5sjdYY07th1fXXe3yvVtm4x43cfsteaJM1Pz5vxB2YfdHPkzifQ9i0nujn23uePaRH8hB0AAAAAAAAwQDiwAwAAAAAAAAYIB3YAAAAAAADAAOHADgAAAAAAABggHNgBAAAAAAAAA4QDOwAAAAAAAGCAcGAHAAAAAAAADJBS4YblshlPKn6qtBHZOeLg5ojtFMrl58iD3SbL7XjP+f2SlGW5GQ/BuRFJkt2m38vcDLV6xYyXSv699EPPjG/ZusGMN+oTbh/l1L7OsYm6m6Okvt0g98+no8i+jr4zNxJvgkqqVKtmvNPpuDmy3H72kTN3JCk4bcoVeywkKYkKl5A1Y/+BFTO+sFBgXTYTM/6ii57r5mhns2b8jv/f37g5GouLZnwiOmjG09R//uVOasbDir+2H2ivN+O1pO3mqJZadjztujnKstv0Y7vud2WvfUnqhSEz3m7V3Bx5bo9pSaNujqFq04xvShbM+Pqwz+3je337XqYP+XWsGtvrbXb9uJvjBSc576i+Pzd6md9mLcoP7rEbdFb9JKldD6P+pH8d84fsHIt2XJLUtWuEIruWJbm9V5KkSM7eMLHHQpJUtutI1PbHvBzsdRNH/n4pbs2b8X7Xrst52X9/xLHdJiuwDy6n9vdLiP0xz7v2+k57zr3OHnb76D70oN2gVaDGNO16l1btOSxJ8ciIGc8Lfb4UabS2zE7Z6y6u2Gtfkjorc2b8vFO3uTlWFu13byu1932S1GvZ82R1yf4WOmHrDrePFz7ndDO+uLTs5rj9/vvN+Fzk1+QNW44345vWjbk58kX73dFM1pnxk886zu1j+fCDdoOS/+2o1F6Xacn/7ltatPd+uVMghrcc5/Yxmzn7OufdI0khc2pQx393HLz7ATN+9hnnuTnOOft5bpsi+Ak7AAAAAAAAYIBwYAcAAAAAAAAMEA7sAAAAAAAAgAHCgR0AAAAAAAAwQDiwAwAAAAAAAAYIB3YAAAAAAADAAOHADgAAAAAAABggHNgBAAAAAAAAA6RUtGGk1IxnuZ8jV2T3EYKbo5/1zXhI/FvKQ9dukNj32rcv4R/bZGY8FLjXclox43FqX6ck5ZE95j313ByK7XPd4eGmGW/U/OtcXW3ZDYJ/nf3MHtPYHgpJUpqWzXiS2Eni2H+umTOHy5WamyNynmsc+evAm6N57i/q6Bg88l9dtsetVvPHfmTUnmelut2HJP3Uz/yUGU96iZvjrq9/2YwvhY4Zn4gPu33UErvelnp+fRhq2+PVl79mlpy6Ppf4kzmP7JocyR7zUOTPyCL7Oktl/16b0YgZX1913oGSxmv3m/Hg3Os/tPznOjdv18uQTLo5pkbte33hqZvcHEOpXU+7fb+u58fon3+WMrtG9GcOuTny1K6ZWXvFzRH3Vu0GK/NujtCz10Ue7OtMWv66SpzNclYqMI9ye21Vm+v8FO22fR19f88VnD1Ev2fPjVAdcvsoD4+Z8cju4h+vw16/+eyimyNu2PFoYdruY49dTyUpze1nkjvvMEnKlp09/7x9nZKkYe9m/TkaOd97a9FQ09lzJf6eulKzxzZv+OO6tDBvxluNBTfH1kn73VtZsfdCWce/zsR57zbr/l7njFNPNuOrFX8fnHfs78/23KybI3YebSmxv5PXD/m1sLfHfr+MjdXdHCur9r2sLvkFdXXFbpOMjJrxXlx1+9i9d58Zr4/749UYtevY1uoWN8fB+/ea8Xse+J6bY9OObW6bIo7NHSYAAAAAAAAwoDiwAwAAAAAAAAYIB3YAAAAAAADAAOHADgAAAAAAABggHNgBAAAAAAAAA4QDOwAAAAAAAGCAcGAHAAAAAAAADJBS8aaRGe12um6GLAT7YhL/Kirl1IyXaw03R+5cRzfY95pU/GFLKlUz3uv549Xt52a8UbX7kCSV7Bxx4p/Z9vp2vCL7OuLEf7BDDa9N5ubII7tNUuA60tSeX2lqP/t2d8Xto+M8+1Kp4uZIS2Uznjj3IUn93B6vbtefo5UCa2GtaQ7Z87027M+zqjPfe3nPzVFK7Dr1M6/5Sf86mjUz/o2b/saML63482x9dcaMN8KUm6PacGpysNeDJGW5XeuyzB4LSQpOP+2SXSyTxK9jzZI9pg3/VlUvz5nxNPLn12xmj/neVftellbrbh9ZMmTGOxP++/ycZzXN+LqyfR+S1Ovbe4IQ+3MjSv02a1Gpaj9DVeznI0lh1XnXVFpujrhi19Tc28hIioO9LpKeHY9jfz8VvBLgvJclSe22Ge43x9wUpTG7TXv2kJsjiu01Ho9sN+N5xa8Riu39UN6097iSpK49pvGMf6/54f1mPCzaNTfKO24fmfNODwXmRuyVO+f9IkkhtttEiV0vJUnZsffzIKXUXpeTm9e7OfqlVTO+XPHnUa9jr5nD+xfdHI1hez73V+19cLnsr+28adfs0XG/joU5ezwO7HnAzdGs2PN5eGzczWE/NSnU7PXQXvD3waW+vf6nZhbcHOMb7TEdlv+eHAmT9nW07RzLwa9BG7afasarNf87qx/Pm/GFyN8bqjxihpda/noMy/f5/RRw7FVUAAAAAAAAYIBxYAcAAAAAAAAMEA7sAAAAAAAAgAHCgR0AAAAAAAAwQDiwAwAAAAAAAAYIB3YAAAAAAADAAOHADgAAAAAAABggHNgBAAAAAAAAA6RUtGGn2zLjcZK4OZI4NePVStnN4bXpZrmbI8uCGR8aHjbjocA5Z5DdR7sduTk6oW3GW+0lN0elYo95CP69zM3Y/QzV7Wdfq1bdPhTs8Sql/vwKzpCWSv50z/PMjPf69vzqZz23jyy3cyT2UEiSul37OuMCKzutVMx4VuBeIvnzeK0ZnbBrUOKXMXnDVipQmuPIngO5um6OF1z0IjM+vnGbGf/7v7nJ7ePB+75jxqvdmptjtDRtxteVOm6OhlOGKlV/vMrJshmPY+fhO+9ASQrec838e11s2Wv7gArU02U7RyuMmvHZasPtY3ikbsafd9KQm2PCecctRn03R6MyasbTir0nkKSkwP2uRaXZeTMeNjfdHP0hex5EVXsuSlLo2esiL7BHjZz3e7LirL2+X0MU7PdqlPvru5TZc76f+XO+ndkFMRnZ6OZIS3a9y1L7PZZ1/fEKmd0mrhT4uYOOPR5xz95rS1K/47RxrlOxv7HLIntjED0J3x6xs/98pCczWmDbF47BvWF91F4PG7ZtcnPsW7jPjM/nU26OuVl7LmbLk26OPYdWzXhF9jyq1v06FjVm7D7G/fk+MWaPafOQP17bt4yY8ZD4c7k2bL//D03b97qyNOf2Mbdit/n+noNujrGW/exPONGfo51Z+9kuO+cK7QJ1rF6z9w2Vkv9MDk09aMYPLB52c2zccqIZ7/dX3BwhmnXbFMFP2AEAAAAAAAADhAM7AAAAAAAAYIBwYAcAAAAAAAAMEA7sAAAAAAAAgAHCgR0AAAAAAAAwQDiwAwAAAAAAAAYIB3YAAAAAAADAACkVb5qZ0Vqt5mZI0oodj/zzwzwPZrzb7bk54iQ146XYvo5+3x4LSep2Oma8XErcHKWa/Xi8PiSp11k14/2uPwWGG0NmvFa17yWOu24finIznCT+3IhKdpt22x4LSQrBnl+l1B6vuMB11ptNM56W/LWU9e1+ilyHInseVyr2epWkKPhrYa1JKvYcyXN7LktS7NS6OLb7kKR+PzLj3hyRpJD1zfizTtlhxrdv/wW3j9u/9T0z/p2v/62bY9++u8344c6sm6Pi1O1K4s/lcmSPVzmya10U+XU/i+x118+rbo48ttt0Ir/u91U2472yXacmJ4fdPk7fMWrGx0b8HKVKw4wPj9h9SFJcGzHjadmvhaXS49hOrSHp3JQZj0fqbo6OPdWUpP47Ue0VO+7s6yQpkr0+k+W23UW3VaAPu87kkV3XJSmN7QELS/YzkaTI2YNGQxNujv7MATOetebNeJw6D17+uopb/rrrOO/K/sR6N0eo2DU1d/aOiQp8mwR77xCcbxdJCs53lhJ/fkWZ/R7LMz+H8mNvb5jXFs14u7Ts5qhvtNflgenDbo65Q/Y8qnhzRNL4hF23W8t2rVtZ9ef7RH/MjOd2uX34Onr2dYwNb/SvY/2kGf/+1AP+dcztM+Ozh2fMeHe7/Z0tSZ1gD8jIpD2ekpQM28/+7qldbo5swa7b7Y79rs1y510tafH795rxctf/Rppanrb7qNvrVZLalXvM+Niovx/vLflnNUXwE3YAAAAAAADAAOHADgAAAAAAABggHNgBAAAAAAAAA4QDOwAAAAAAAGCAcGAHAAAAAAAADBAO7AAAAAAAAIABwoEdAAAAAAAAMEA4sAMAAAAAAAAGSKlow7F16814kpbdHHlsnw+GLHdzhNxuU01TN0dcstt0Om0znvU6bh9Zv2fGo5C4OUpJ5DTwz1vLZfu5JEnVzZFEXj99M9pqL/t9OPeSlCpujiB7vJaWl9wczeawGc8iezxj75lJCnmw45E/NxTb/XQzuw9JiiI7h7dOJEl54RKyZtSq9rj1c//5BefxtFv2mno4ibNmEv/ZJM589a6zUffr/vNf+GwzfsYZp7o59jz4oBPf6+bYt9duMzc/4+boOe+GNNjPLZb/jvNKSBT8HFl5yIyXqzU3x4ZR+9lu32D3Mblu3O2jMWq3qdabbo6K06Zc8d9xsbNviBP/XRs79XStylN7PoaFKTdHObXf70m54eboLc+Z8VKn6+aoOnvQpLNqxuM8c/uIY+f9n/m1Pzh70NKCfZ0P92PXsv6SXw/Lq/NmPHHGo1Pxn2sW2Tki+fuUUBkx4+UhOy5J6abtZnxpyp7nYdFfB8qc+VPy63Y0ss6MJyMTbo6+894P3sZAkgo0WWuiRsuMr4QDbo72qv2d0pn1a0zo2d+foebn6CV2LRyesNdMZ7Hu9jE+dJwZbzb8ddl21oxzG5Kkw8634dzygpujl6+Y8aX5RTPe3uZfaFq39zIlp1ZKUux8now2Jt0c++ftb/rpxXkzHvr+Xinq2+/rPPbHa2y9PX+izF4nkqSS856M/e+s2Rn/DKQIfsIOAAAAAAAAGCAc2AEAAAAAAAADhAM7AAAAAAAAYIBwYAcAAAAAAAAMEA7sAAAAAAAAgAHCgR0AAAAAAAAwQDiwAwAAAAAAAAZIFEIIT/dFAAAAAAAAAHgYP2EHAAAAAAAADBAO7AAAAAAAAIABwoEdAAAAAAAAMEA4sAMAAAAAAAAGCAd2AAAAAAAAwADhwA4AAAAAAAAYIBzYAQAAAAAAAAOEAzsAAAAAAABggHBgBwAAAAAAAAyQ/z+ts6bA0MKUowAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Load Dataset (CIFAR-100)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # insert more transformations of data i.e. normalization\n",
        "])\n",
        "\n",
        "train_data = torchvision.datasets.CIFAR100(root='./data', train=True, transform = transform, download = True)\n",
        "test_data = torchvision.datasets.CIFAR100(root='./data', train=False, transform = transform, download = True)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size = Mini_batch, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size = Mini_batch, shuffle=False)\n",
        "\n",
        "# view a couple of sample images to make sure they are loaded\n",
        "\n",
        "def display_img_examples(loader):\n",
        "  images, labels = next(iter(loader))\n",
        "  images = images.cpu().detach().numpy()\n",
        "  plt.figure(figsize=(16, 4))\n",
        "  for i in range(4):\n",
        "    plt.subplot(1, 4, i+1)\n",
        "    plt.imshow(np.transpose(images[i], (1, 2, 0)))\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Image of class {labels[i].item()}\")\n",
        "  plt.show()\n",
        "\n",
        "print(\"Train Loader Images:\")\n",
        "display_img_examples(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYFPnx-iv1X7"
      },
      "outputs": [],
      "source": [
        "class FeatureDataset(Dataset):\n",
        "    def __init__(self, features=torch.zeros((0, 2048), dtype=torch.float32), labels=torch.zeros(0)):\n",
        "        self.features = features\n",
        "        self.labels = labels.long()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        feature = self.features[idx]\n",
        "        label = self.labels[idx]\n",
        "        return feature, label\n",
        "\n",
        "    def add_features(self, new_features, new_labels):\n",
        "        self.features = torch.cat((self.features, new_features), dim=0)\n",
        "        self.labels = torch.cat((self.labels, new_labels), dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DELM3i7tA5fF"
      },
      "outputs": [],
      "source": [
        "def dataloader_to_dataset(dataloader):\n",
        "    # Initialize lists to store features and labels\n",
        "    all_features = []\n",
        "    all_labels = []\n",
        "\n",
        "    # Process all batches\n",
        "    for features, labels in dataloader:\n",
        "        all_features.append(features)\n",
        "        all_labels.append(labels)\n",
        "\n",
        "    # Concatenate all features and labels\n",
        "    all_features = torch.cat(all_features)\n",
        "    all_labels = torch.cat(all_labels)\n",
        "\n",
        "    # Create a new FeatureDataset from the concatenated features and labels\n",
        "    dataset = FeatureDataset(all_features, all_labels)\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4quizRWqeSl_"
      },
      "outputs": [],
      "source": [
        "# Resnet processing\n",
        "\n",
        "resnet = resnet50(pretrained=True)\n",
        "resnet.eval()\n",
        "\n",
        "resnet_feature_extractor = nn.Sequential(*list(resnet.children())[:-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCPokNsZO27Z",
        "outputId": "b5c078af-6397-4322-f5a3-1ddd75bce07b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training features shape: torch.Size([50000, 2048])\n",
            "Training labels shape: torch.Size([50000])\n",
            "Test features shape: torch.Size([10000, 2048])\n",
            "Test labels shape: torch.Size([10000])\n"
          ]
        }
      ],
      "source": [
        "# pass data through Resnet processing\n",
        "class CIFAR100FeatureDataset(Dataset):\n",
        "    def __init__(self, dataset):\n",
        "        self.dataset = dataset\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image, label = self.dataset[idx]\n",
        "        return image, label\n",
        "\n",
        "# training data\n",
        "num_images = len(train_data)\n",
        "feature_vectors = torch.zeros((num_images, 2048))\n",
        "labels = torch.zeros(num_images)\n",
        "\n",
        "feature_dataset = CIFAR100FeatureDataset(train_data)\n",
        "feature_loader = DataLoader(feature_dataset, batch_size=Mini_batch, shuffle=False)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, (images, labels_batch) in enumerate(feature_loader):\n",
        "        images = images\n",
        "        labels_batch = labels_batch\n",
        "        features_batch = resnet_feature_extractor(images).squeeze()\n",
        "        start_index = i * Mini_batch\n",
        "        end_index = start_index + features_batch.shape[0]\n",
        "        feature_vectors[start_index:end_index] = features_batch\n",
        "        labels[start_index:end_index] = labels_batch\n",
        "\n",
        "feature_vectors = torch.tensor(feature_vectors, dtype=torch.float32)\n",
        "labels = torch.tensor(labels).long()\n",
        "\n",
        "print(\"Training features shape:\", feature_vectors.shape)\n",
        "print(\"Training labels shape:\", labels.shape)\n",
        "\n",
        "# testing data\n",
        "num_images = len(test_data)\n",
        "test_feature_vectors = torch.zeros((num_images, 2048))\n",
        "test_labels = torch.zeros(num_images)\n",
        "\n",
        "test_feature_dataset = CIFAR100FeatureDataset(test_data)\n",
        "test_feature_loader = DataLoader(test_feature_dataset, batch_size=Mini_batch, shuffle=False)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, (images, labels_batch) in enumerate(test_feature_loader):\n",
        "        features_batch = resnet_feature_extractor(images).squeeze()\n",
        "        start_index = i * Mini_batch\n",
        "        end_index = start_index + features_batch.shape[0]\n",
        "        test_feature_vectors[start_index:end_index] = features_batch\n",
        "        test_labels[start_index:end_index] = labels_batch\n",
        "\n",
        "test_feature_vectors = torch.tensor(test_feature_vectors, dtype=torch.float32)\n",
        "test_labels = torch.tensor(test_labels).long()\n",
        "\n",
        "print(\"Test features shape:\", test_feature_vectors.shape)\n",
        "print(\"Test labels shape:\", test_labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate the Performance of Resnet on CIFAR-100"
      ],
      "metadata": {
        "id": "ohGjABSpCxba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_test = resnet50(pretrained=True)\n",
        "num_features = resnet_test.fc.in_features\n",
        "resnet_test.fc = nn.Linear(num_features, 100)"
      ],
      "metadata": {
        "id": "VXTL8OXqDDNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(resnet_test.parameters(), lr=0.001)\n",
        "\n",
        "# training function\n",
        "def training_step(model, data_loader, criterion, optimizer):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for images, labels in data_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    average_loss = total_loss / len(data_loader)\n",
        "    return average_loss\n",
        "\n",
        "# calculate accuracy\n",
        "def calc_accuracy(model, data_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy\n",
        "\n",
        "# training\n",
        "num_epochs = 30\n",
        "for epoch in range(num_epochs):\n",
        "    avg_loss = training_step(resnet_test, train_loader, criterion, optimizer)\n",
        "    accuracy = calc_accuracy(resnet_test, test_loader)\n",
        "    print(f\"Epoch {epoch+1}, Loss: {avg_loss}, Accuracy: {accuracy}%\")"
      ],
      "metadata": {
        "id": "BxmYzBERDDUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test accuracy\n",
        "\n",
        "def evaluate_model(model, data_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy\n",
        "\n",
        "# Evaluate the model\n",
        "test_accuracy = evaluate_model(resnet_test, test_loader)\n",
        "print(f'Test Accuracy of the model on the 10000 test images: {test_accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "rxFSz4IHDDad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfYC56dhLO8u"
      },
      "source": [
        "# Hippocampus Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLWq-gNEtX_6"
      },
      "outputs": [],
      "source": [
        "# define HC\n",
        "\n",
        "class HC(nn.Module):\n",
        "  def __init__(self, classifier_dims = Classifier_Dims, learning_rate= Learning_Rate, p_dropout=Dropout):\n",
        "    super(HC, self).__init__()\n",
        "\n",
        "    self.short_term_memory = FeatureDataset()\n",
        "\n",
        "    self.classifier_layers = []\n",
        "    self.current_dim = classifier_dims[0]\n",
        "\n",
        "    if len(classifier_dims)!=1:\n",
        "      # Avoid dropping out the first layer of processing and output layer\n",
        "      self.classifier_layers.append(nn.Linear(self.current_dim, classifier_dims[0]))\n",
        "      self.classifier_layers.append(nn.ReLU())\n",
        "\n",
        "      for i in range(1, len(classifier_dims)-1):\n",
        "        self.hidden_dim = classifier_dims[i]\n",
        "        self.classifier_layers.append(nn.Linear(self.current_dim, self.hidden_dim))\n",
        "        self.classifier_layers.append(nn.ReLU())\n",
        "        self.classifier_layers.append(nn.Dropout(p=p_dropout))\n",
        "        self.current_dim = self.hidden_dim\n",
        "\n",
        "    self.classifier_layers.append(nn.Linear(self.current_dim, classifier_dims[len(classifier_dims)-1]))\n",
        "\n",
        "    self.classifier = nn.Sequential(*self.classifier_layers)\n",
        "\n",
        "    # Using Adam Optimizer\n",
        "    self.optimizer = optim.Adam(self.parameters(), lr = learning_rate)\n",
        "    self.CrossEntropyLoss = nn.CrossEntropyLoss()\n",
        "\n",
        "  def forward(self, x, y = None, is_storing = False):\n",
        "    if (is_storing):\n",
        "      features = x\n",
        "      labels = y\n",
        "      self.short_term_memory.add_features(x, y)\n",
        "    class_logits = self.classifier(x)\n",
        "    return class_logits\n",
        "\n",
        "  def clear_memory(self):\n",
        "    memory = self.short_term_memory\n",
        "    self.short_term_memory = FeatureDataset(features=torch.tensor([]), labels=torch.tensor([]))\n",
        "    return memory\n",
        "\n",
        "  def training_step(self, dataloader):\n",
        "    total_loss = 0\n",
        "\n",
        "    self.train()\n",
        "    optimizer = self.optimizer\n",
        "\n",
        "    for features, targets in dataloader:\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      class_logits = self.forward(features, targets, is_storing=True)\n",
        "      loss = self.CrossEntropyLoss(class_logits, targets)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      total_loss += loss\n",
        "\n",
        "    return (total_loss / (len(dataloader) * dataloader.batch_size))\n",
        "\n",
        "  def calc_accuracy(self, dataloader):\n",
        "    total_correct = 0\n",
        "\n",
        "    self.eval()\n",
        "    with torch.no_grad():\n",
        "      for features, targets in dataloader:\n",
        "        predictions = self.forward(features, targets, is_storing=False)\n",
        "        predictions = torch.argmax(predictions, dim=1)\n",
        "\n",
        "        correct = (predictions == targets).sum().item()\n",
        "        total_correct += correct\n",
        "\n",
        "    return (total_correct / (len(dataloader) * dataloader.batch_size))*100\n",
        "\n",
        "  def calculate_average_examples_per_class(self):\n",
        "    class_counts = defaultdict(int)\n",
        "\n",
        "    for label in self.short_term_memory.labels:\n",
        "      class_counts[label.item()] += 1\n",
        "\n",
        "    total_examples = sum(class_counts.values())\n",
        "    total_classes = len(class_counts)\n",
        "\n",
        "    average_examples_per_class = math.ceil(total_examples / total_classes) if total_classes > 0 else 0\n",
        "    return average_examples_per_class\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iAOTMobLSnf"
      },
      "source": [
        "# Pre-frontal Cortex  Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9213wTvFtRdp"
      },
      "outputs": [],
      "source": [
        "# define mPFC (long term)\n",
        "\n",
        "class mPFC(nn.Module):\n",
        "  def __init__(self, input_dim=Input_Dim, autoencoder_hidden_dims = Autoencoder_Hidden_Dims, classifier_dims = mPFC_Classifier_Dims, lambda_values=Lambda_Values, learning_rate=Learning_Rate):\n",
        "    super(mPFC, self).__init__()\n",
        "    # encoder\n",
        "    self.encoder_layers = []\n",
        "    self.current_dim = input_dim\n",
        "    self.encoder_layers.append(nn.ELU())\n",
        "    for hidden_dim in autoencoder_hidden_dims:\n",
        "      self.encoder_layers.append(nn.Linear(self.current_dim, hidden_dim))\n",
        "      self.encoder_layers.append(nn.ELU())\n",
        "      self.current_dim = hidden_dim\n",
        "    self.encoder = nn.Sequential(*self.encoder_layers)\n",
        "\n",
        "    # decoder\n",
        "    self.decoder_layers = []\n",
        "    self.hidden_dims_reversed = list(autoencoder_hidden_dims[::-1])\n",
        "    for hidden_dim in self.hidden_dims_reversed:\n",
        "      self.decoder_layers.append(nn.Linear(self.current_dim, hidden_dim))\n",
        "      self.decoder_layers.append(nn.ELU())\n",
        "      self.current_dim = hidden_dim\n",
        "    self.decoder_layers.append(nn.Linear(self.current_dim, input_dim))\n",
        "    self.decoder_layers.append(nn.ELU())\n",
        "    self.decoder = nn.Sequential(*self.decoder_layers)\n",
        "\n",
        "    #classifier\n",
        "    self.current_dim = autoencoder_hidden_dims[-1]\n",
        "    self.classifier_layers= []\n",
        "\n",
        "    if len(classifier_dims) != 1:\n",
        "      self.classifier_layers.append(nn.Linear(self.current_dim, classifier_dims[0]))\n",
        "      self.classifier_layers.append(nn.ELU())\n",
        "      self.current_dim = classifier_dims[0]\n",
        "\n",
        "      for i in range(1, len(classifier_dims)-1):\n",
        "        self.hidden_dim = classifier_dims[i]\n",
        "        self.classifier_layers.append(nn.Linear(self.current_dim, hidden_dim))\n",
        "        self.classifier_layers.append(nn.ELU())\n",
        "        self.classifier_layers.append(nn.Dropout(p=Dropout))\n",
        "        self.current_dim = hidden_dim\n",
        "\n",
        "    self.classifier_layers.append(nn.Linear(self.current_dim, classifier_dims[len(classifier_dims)-1]))\n",
        "\n",
        "    self.classifier = nn.Sequential(*self.classifier_layers)\n",
        "\n",
        "    # lambda\n",
        "    self.lambda_values = torch.tensor(lambda_values if lambda_values else [1.0] * len(autoencoder_hidden_dims), dtype=torch.float32)\n",
        "\n",
        "    # optimizer\n",
        "    self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
        "\n",
        "    #session number\n",
        "    self.class_means = defaultdict(list)\n",
        "    self.class_covariances = defaultdict(list)\n",
        "\n",
        "    self.input_dim = input_dim\n",
        "\n",
        "  def encoder_forward(self, x):\n",
        "    encoder_intermediates = [x]\n",
        "    for layer in self.encoder:\n",
        "      x = layer(x)\n",
        "      encoder_intermediates.append(x)\n",
        "    encoded = encoder_intermediates[-1]\n",
        "    return encoded, encoder_intermediates\n",
        "\n",
        "  def decoder_forward(self, x):\n",
        "    decoder_intermediates = [x]\n",
        "    for layer in self.decoder:\n",
        "      x = layer(x)\n",
        "      decoder_intermediates.append(x)\n",
        "    pseudo_img = decoder_intermediates[-1]\n",
        "    return pseudo_img, list(decoder_intermediates[::-1])\n",
        "\n",
        "  def classify(self, x):\n",
        "    class_logits = self.classifier(x)\n",
        "    return class_logits\n",
        "\n",
        "  def compute_loss(self, class_logits, targets, encoder_intermediates, decoder_intermediates):\n",
        "    # classification loss\n",
        "    classification_loss = nn.CrossEntropyLoss()(class_logits, targets)\n",
        "\n",
        "    # reconstruction loss with lambda weighting\n",
        "    reconstruction_loss = 0\n",
        "    for i in range(len(self.lambda_values)):\n",
        "      encoder_hidden = encoder_intermediates[i]\n",
        "      decoder_hidden = decoder_intermediates[i]\n",
        "      diff = encoder_hidden - decoder_hidden\n",
        "      squared_diff = diff.pow(2)\n",
        "      layer_loss = squared_diff.sum()\n",
        "      reconstruction_loss += self.lambda_values[i] * layer_loss\n",
        "\n",
        "    # total loss\n",
        "    total_loss = classification_loss + reconstruction_loss\n",
        "\n",
        "    return classification_loss, reconstruction_loss, total_loss\n",
        "\n",
        "  def training_step(self, data_loader):\n",
        "    self.train()\n",
        "\n",
        "    total_classification_loss = 0\n",
        "    total_reconstruction_loss = 0\n",
        "    total_total_loss = 0\n",
        "\n",
        "    for x, targets in data_loader:\n",
        "      # forward pass\n",
        "      encoded, encoder_intermediates = self.encoder_forward(x)\n",
        "      pseudo_img, decoder_intermediates = self.decoder_forward(encoded)\n",
        "      class_logits = self.classify(encoded)\n",
        "\n",
        "      # compute losses\n",
        "      classification_loss, reconstruction_loss, total_loss = self.compute_loss(\n",
        "        class_logits, targets, encoder_intermediates, decoder_intermediates\n",
        "      )\n",
        "\n",
        "      # zero gradients\n",
        "      self.optimizer.zero_grad()\n",
        "\n",
        "      # backward pass\n",
        "      classification_loss.backward(retain_graph=True)\n",
        "      classifier_grads = {name: param.grad.clone() for name, param in self.classifier.named_parameters()}\n",
        "      reconstruction_loss.backward(retain_graph=True)\n",
        "      decoder_grads = {name: param.grad.clone() for name, param in self.decoder.named_parameters()}\n",
        "      total_loss.backward()\n",
        "      encoder_grads = {name: param.grad.clone() for name, param in self.encoder.named_parameters()}\n",
        "\n",
        "      # optimizer\n",
        "      encoder_optimizer = optim.Adam(self.encoder.parameters(), lr=self.optimizer.defaults['lr'])\n",
        "      encoder_optimizer.step()\n",
        "      classifier_optimizer = optim.Adam(self.classifier.parameters(), lr=self.optimizer.defaults['lr'])\n",
        "      classifier_optimizer.step()\n",
        "      decoder_optimizer = optim.Adam(self.decoder.parameters(), lr=self.optimizer.defaults['lr'])\n",
        "      decoder_optimizer.step()\n",
        "\n",
        "      # update parameters\n",
        "      for name, param in self.classifier.named_parameters():\n",
        "        if param.grad is not None:\n",
        "          param.grad.data = classifier_grads[name].data\n",
        "      for name, param in self.decoder.named_parameters():\n",
        "        if param.grad is not None:\n",
        "          param.grad.data = decoder_grads[name].data\n",
        "      for name, param in self.encoder.named_parameters():\n",
        "        if param.grad is not None:\n",
        "          param.grad.data = encoder_grads[name].data\n",
        "\n",
        "      # add losses to total\n",
        "      total_classification_loss += classification_loss.item()\n",
        "      total_reconstruction_loss += reconstruction_loss.item()\n",
        "      total_total_loss += total_loss.item()\n",
        "\n",
        "    # average loss\n",
        "    average_classification_loss = total_classification_loss / len(data_loader)\n",
        "    average_reconstruction_loss = total_reconstruction_loss / len(data_loader)\n",
        "    average_total_loss = total_total_loss / len(data_loader)\n",
        "\n",
        "    return average_classification_loss, average_reconstruction_loss, average_total_loss\n",
        "\n",
        "  def consolidate_statistics(self):\n",
        "    # compute the average mean vector and covariance matrix for each class\n",
        "    for label in self.class_means:\n",
        "      if isinstance(self.class_means[label], list) and len(self.class_means[label]) > 0:\n",
        "        means = torch.stack(self.class_means[label])\n",
        "        covariances = torch.stack(self.class_covariances[label])\n",
        "\n",
        "        # Average the mean vectors and covariance matrices\n",
        "        consolidated_mean = means.mean(dim=0)\n",
        "        consolidated_covariance = covariances.mean(dim=0)\n",
        "\n",
        "        # Update the consolidated statistics\n",
        "        self.class_means[label] = []\n",
        "        self.class_means[label].append(consolidated_mean)\n",
        "        self.class_covariances[label] = []\n",
        "        self.class_covariances[label].append(consolidated_covariance)\n",
        "\n",
        "      elif isinstance(self.class_means[label], torch.Tensor):\n",
        "        # If the statistics are already in tensor form, no need to stack\n",
        "        consolidated_mean = self.class_means[label]\n",
        "        consolidated_covariance = self.class_covariances[label] if isinstance(self.class_covariances[label], torch.Tensor) else torch.zeros_like(consolidated_mean)\n",
        "\n",
        "        # Update the consolidated statistics\n",
        "        self.class_means[label] = []\n",
        "        self.class_means[label].append(consolidated_mean)\n",
        "        self.class_covariances[label] = []\n",
        "        self.class_covariances[label].append(consolidated_covariance)\n",
        "\n",
        "  def compute_covariance_matrix(self, features):\n",
        "    # Compute mean vector and covariance matrix\n",
        "    mean_vector = features.mean(dim=0)\n",
        "    centered_features = features - mean_vector\n",
        "    covariance_matrix = torch.mm(centered_features.t(), centered_features) / (features.size(0) - 1)\n",
        "\n",
        "    # Ensure covariance matrix is positive definite using Cholesky decomposition\n",
        "    epsilon = 1e-5\n",
        "    attempts = 0\n",
        "    max_attempts = 10\n",
        "    while attempts < max_attempts:\n",
        "        try:\n",
        "            # Attempt Cholesky decomposition\n",
        "            torch.linalg.cholesky(covariance_matrix)\n",
        "            break\n",
        "        except RuntimeError:\n",
        "            # If decomposition fails, add a larger epsilon to the diagonal\n",
        "            epsilon *= 10\n",
        "            covariance_matrix += epsilon * torch.eye(covariance_matrix.size(0))\n",
        "\n",
        "        attempts += 1\n",
        "\n",
        "    if attempts == max_attempts:\n",
        "        raise ValueError(\"Covariance matrix could not be made positive definite\")\n",
        "\n",
        "    return covariance_matrix\n",
        "\n",
        "  def generate_statistics(self, feature_vectors, labels):\n",
        "    # Dictionary to hold features for each class\n",
        "    class_features = defaultdict(list)\n",
        "\n",
        "    # Organize features by class\n",
        "    for i in range(len(labels)):\n",
        "        label = labels[i].item()  # Ensure label is a scalar\n",
        "        feature_vector = feature_vectors[i]\n",
        "\n",
        "        # Append feature vector to the corresponding class list\n",
        "        class_features[label].append(feature_vector)\n",
        "\n",
        "    # Process each class\n",
        "    for label, features in class_features.items():\n",
        "        features = torch.stack(features)\n",
        "        # Compute covariance matrix using the updated function\n",
        "        covariance_matrix = self.compute_covariance_matrix(features)\n",
        "        # Initialize lists for means and covariances if not already present\n",
        "        if label not in self.class_means:\n",
        "            self.class_means[label] = []\n",
        "        if label not in self.class_covariances:\n",
        "            self.class_covariances[label] = []\n",
        "\n",
        "        # Compute mean vector for the class\n",
        "        mean_vector = features.mean(dim=0)\n",
        "\n",
        "        # Append mean vector and covariance matrix to class statistics\n",
        "        self.class_means[label].append(mean_vector)\n",
        "        self.class_covariances[label].append(covariance_matrix)\n",
        "\n",
        "    # Consolidate the collected statistics\n",
        "    self.consolidate_statistics()\n",
        "\n",
        "  def pseudoimg_from_statistics(self, num_examples_per_class):\n",
        "    self.eval()\n",
        "\n",
        "    pseudo_examples = []\n",
        "    pseudo_labels = []\n",
        "\n",
        "    for label, mean_vector in self.class_means.items():\n",
        "      if isinstance(mean_vector, torch.Tensor):\n",
        "        covariance_matrix = self.class_covariances[label]\n",
        "\n",
        "        # create a multivariate normal distribution\n",
        "        mvn = dist.MultivariateNormal(mean_vector, covariance_matrix)\n",
        "\n",
        "        # generate pseudo-examples\n",
        "        examples = mvn.sample((num_examples_per_class,))\n",
        "        labels = torch.full((num_examples_per_class,), label, dtype=torch.long)\n",
        "\n",
        "        pseudo_examples.append(examples)\n",
        "        pseudo_labels.append(labels)\n",
        "\n",
        "    if len(pseudo_examples) == 0 or len(pseudo_labels) == 0:\n",
        "      pseudo_examples = torch.empty((0, self.input_dim))\n",
        "      pseudo_labels = torch.empty((0,), dtype=torch.long)\n",
        "    else:\n",
        "      pseudo_examples = torch.cat(pseudo_examples)\n",
        "      pseudo_labels = torch.cat(pseudo_labels)\n",
        "\n",
        "    return pseudo_examples, pseudo_labels\n",
        "\n",
        "  def calculate_accuracy(self, data_loader):\n",
        "    self.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for x, targets in data_loader:\n",
        "        encoded, _ = self.encoder_forward(x)\n",
        "        class_logits = self.classify(encoded)\n",
        "        _, predicted = torch.max(class_logits.data, 1)\n",
        "        total += targets.size(0)\n",
        "        correct += (predicted == targets).sum().item()\n",
        "        # print('l')\n",
        "        # breakpoint()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy\n",
        "\n",
        "mpfc = mPFC(Input_Dim, Autoencoder_Hidden_Dims, Classifier_Dims, [1e4, 1, 0.1], 5e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKg46QH1Lefr"
      },
      "source": [
        "# BLA Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGy_SZT9tdgY"
      },
      "outputs": [],
      "source": [
        "# Define BLA\n",
        "\n",
        "class BLA(nn.Module):\n",
        "\n",
        "  def __init__(self, classifier_dims = Classifier_Dims, learning_rate= Learning_Rate, p_dropout=Dropout):\n",
        "    super(BLA, self).__init__()\n",
        "\n",
        "    self.classifier_layers = []\n",
        "    self.current_dim = classifier_dims[0]\n",
        "\n",
        "    if len(classifier_dims)!=1:\n",
        "      # Avoid dropping out the first layer of processing and output layer\n",
        "      self.classifier_layers.append(nn.Linear(self.current_dim, classifier_dims[0]))\n",
        "      self.classifier_layers.append(nn.ReLU())\n",
        "\n",
        "      for i in range(1, len(classifier_dims)):\n",
        "        self.hidden_dim = classifier_dims[i]\n",
        "        self.classifier_layers.append(nn.Linear(self.current_dim, self.hidden_dim))\n",
        "        self.classifier_layers.append(nn.ReLU())\n",
        "        self.classifier_layers.append(nn.Dropout(p=p_dropout))\n",
        "        self.current_dim = self.hidden_dim\n",
        "\n",
        "    self.classifier_layers.append(nn.Linear(self.current_dim, 1))\n",
        "\n",
        "    self.classifier = nn.Sequential(*self.classifier_layers)\n",
        "\n",
        "    # Using Adam Optimizer\n",
        "    self.optimizer = optim.Adam(self.parameters(), lr = learning_rate)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    class_logits = self.classifier(x)\n",
        "    return class_logits\n",
        "\n",
        "  def training_step(self, dataloader, HC, mPFC):\n",
        "    total_loss = 0\n",
        "    self.train()\n",
        "    HC.eval()\n",
        "    mPFC.eval()\n",
        "\n",
        "    for features, labels in dataloader:\n",
        "        HC_logits = []\n",
        "        mPFC_logits = []\n",
        "\n",
        "        # Forward pass for HC and mPFC models\n",
        "        with torch.no_grad():\n",
        "            HC_logits = HC.forward(features)\n",
        "            encoded, _ = mPFC.encoder_forward(features)\n",
        "            mPFC_logits = mPFC.classify(encoded)\n",
        "\n",
        "        # Get the optimizer\n",
        "        optimizer = self.optimizer\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Compute class probabilities from BLA\n",
        "        class_logits = self.forward(features)\n",
        "        class_prob = torch.sigmoid(class_logits)\n",
        "\n",
        "        # Create target tensor based on source information\n",
        "        BLA_target = labels.float().view(-1, 1)  # Convert source information to float tensor\n",
        "\n",
        "        # Compute BLA loss\n",
        "        BLA_loss = nn.BCELoss()(class_prob, BLA_target)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        BLA_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate total loss\n",
        "        total_loss += BLA_loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "  def calc_accuracy(self, dataloader):\n",
        "    total_correct = 0\n",
        "\n",
        "    self.eval()\n",
        "    with torch.no_grad():\n",
        "      for features, targets in dataloader:\n",
        "        predictions = self.forward(features)\n",
        "        predictions = torch.argmax(predictions, dim=1)\n",
        "\n",
        "        correct = (predictions == targets).sum().item()\n",
        "        total_correct += correct\n",
        "\n",
        "    return (total_correct / (len(dataloader) * dataloader.batch_size))*100\n",
        "\n",
        "\n",
        "Bla = BLA()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_M6temMLhK_"
      },
      "source": [
        "# Dual Memory System Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbTayHs7f67G"
      },
      "outputs": [],
      "source": [
        "# base knowledge dataloader\n",
        "\n",
        "def sort_by_class(feature_vectors, labels):\n",
        "  # Sort labels and get the sorted indices\n",
        "  sorted_labels, indices = torch.sort(labels)\n",
        "\n",
        "  # Use the sorted indices to sort the feature vectors\n",
        "  sorted_feature_vectors = feature_vectors[indices]\n",
        "\n",
        "  return sorted_feature_vectors, sorted_labels\n",
        "\n",
        "sorted_feature_vectors, sorted_labels = sort_by_class(feature_vectors, labels)\n",
        "half = int(len(sorted_labels)/2)\n",
        "base_dataset = FeatureDataset(sorted_feature_vectors[:half], sorted_labels[:half])\n",
        "base_dataloader = DataLoader(base_dataset, batch_size=Mini_batch, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_dX6yZDtixQ"
      },
      "outputs": [],
      "source": [
        "# dmsm\n",
        "\n",
        "class DMSM(nn.Module):\n",
        "  def __init__(self, input_dim=Input_Dim, autoencoder_dims = Autoencoder_Hidden_Dims, classifier_dims = Classifier_Dims, mpfc_classifier_dims = mPFC_Classifier_Dims, learning_rate=Learning_Rate, p_dropout=Dropout, mpfc_base_epochs = mPFC_Base_Epochs, lambda_values = Lambda_Values, dataloader = base_dataloader):\n",
        "    super(DMSM, self).__init__()\n",
        "\n",
        "    self.hc = HC(classifier_dims, learning_rate, p_dropout)\n",
        "    self.bla = BLA(classifier_dims, learning_rate, p_dropout)\n",
        "    self.mpfc = mPFC(input_dim, autoencoder_dims, mpfc_classifier_dims, lambda_values, learning_rate)\n",
        "    self.mpfc_base_epochs = mpfc_base_epochs\n",
        "    self.dataloader = base_dataloader\n",
        "\n",
        "  def base_knowledge(self):\n",
        "    for _ in range(self.mpfc_base_epochs):\n",
        "      accuracy = self.mpfc.calculate_accuracy(self.dataloader)\n",
        "      avg_classification_loss, avg_reconstruction_loss, avg_total_loss = self.mpfc.training_step(self.dataloader)\n",
        "      print(f\"Total Loss: {avg_total_loss}, Classification Loss: {avg_classification_loss}, Reconstruction Loss: {avg_reconstruction_loss}\")\n",
        "      # for param_group in self.mpfc.optimizer.param_groups:\n",
        "      #    print(\"Learning rate:\", param_group['lr'])\n",
        "      # for name, param in self.mpfc.named_parameters():\n",
        "      #     if param.grad is not None:\n",
        "      #         print(f\"{name} gradient norm: {param.grad.norm().item()}\")\n",
        "      print(f\"Accuracy: {accuracy}%\")\n",
        "\n",
        "    base_knowledge_dataset = dataloader_to_dataset(base_dataloader)\n",
        "\n",
        "    self.mpfc.generate_statistics(base_knowledge_dataset.features, base_knowledge_dataset.labels)\n",
        "\n",
        "  def training_session(self, dataset = None, BLA_epochs = BLA_Epochs):\n",
        "    mpfc = self.mpfc\n",
        "    hc = self.hc\n",
        "    bla = self.bla\n",
        "\n",
        "    dataloader_class = DataLoader(dataset, Mini_batch, shuffle = True)\n",
        "\n",
        "    #Train HC\n",
        "    for epoch in range(BLA_Epochs):\n",
        "      loss = hc.training_step(dataloader_class)\n",
        "      #print(f\"hc loss: {loss}\")\n",
        "      accuracy = hc.calc_accuracy(dataloader_class)\n",
        "      #print(f\"hc Epoch {epoch+1}, Accuracy: {accuracy}%\")\n",
        "\n",
        "    #Integrate hallucinated images into the dataloader\n",
        "    pseudo_examples, pseudo_labels = mpfc.pseudoimg_from_statistics(hc.calculate_average_examples_per_class())\n",
        "\n",
        "    source_labels = torch.ones_like(pseudo_labels)\n",
        "    dataset_source = FeatureDataset(pseudo_examples, source_labels)\n",
        "\n",
        "    dataset_source.add_features(dataset.features, torch.zeros_like(dataset.labels))\n",
        "    dataloader_source = DataLoader(dataset_source, Mini_batch, shuffle = True)\n",
        "\n",
        "    #Train BLA\n",
        "    for epoch in range(BLA_epochs):\n",
        "      loss = bla.training_step(dataloader_source, self.hc, self.mpfc)\n",
        "      # print(f\"bla loss: {loss}\")\n",
        "      accuracy = bla.calc_accuracy(dataloader_source)\n",
        "      # print(f\"bla Epoch {epoch+1}, Accuracy: {accuracy}%\")\n",
        "\n",
        "  def sleep(self, mem_cons_epochs = Mem_Cons_Epochs):\n",
        "    mpfc = self.mpfc\n",
        "    hc = self.hc\n",
        "    bla = self.bla\n",
        "\n",
        "    # integrate hallucinated images into short term memory data\n",
        "    pseudo_examples, pseudo_labels = mpfc.pseudoimg_from_statistics(hc.calculate_average_examples_per_class())\n",
        "    short_term_data = hc.clear_memory()\n",
        "    short_term_data.add_features(pseudo_examples, pseudo_labels)\n",
        "    training_dataloader = DataLoader(short_term_data, Mini_batch, shuffle = True)\n",
        "\n",
        "    for epoch in range(mem_cons_epochs):\n",
        "      mpfc.training_step(training_dataloader)\n",
        "      #print(f\"sleep epoch: {epoch}\")\n",
        "      accuracy = self.mpfc.calculate_accuracy(self.dataloader)\n",
        "      avg_classification_loss, avg_reconstruction_loss, avg_total_loss = self.mpfc.training_step(self.dataloader)\n",
        "      # print(f\"Total Loss: {avg_total_loss}, Classification Loss: {avg_classification_loss}, Reconstruction Loss: {avg_reconstruction_loss}\")\n",
        "      # print(f\"Accuracy: {accuracy}%\")\n",
        "\n",
        "    examples = short_term_data.features\n",
        "    labels = short_term_data.labels\n",
        "    mpfc.generate_statistics(examples, labels)\n",
        "\n",
        "  def eval(self, dataset):\n",
        "    print(\"entered\")\n",
        "    mpfc = self.mpfc\n",
        "    hc = self.hc\n",
        "    bla = self.bla\n",
        "\n",
        "    hc.eval()\n",
        "    mpfc.eval()\n",
        "    bla.eval()\n",
        "\n",
        "    all_inputs = []\n",
        "    all_targets = []\n",
        "\n",
        "    for inputs, targets in dataset:\n",
        "      all_inputs.append(inputs)\n",
        "      all_targets.append(targets)\n",
        "\n",
        "    all_inputs = torch.stack(all_inputs)\n",
        "    all_targets = torch.stack(all_targets)\n",
        "\n",
        "    predictions = []\n",
        "    for input in all_inputs:\n",
        "      predictions.append(bla.forward(input))\n",
        "    predictions_rounded = torch.round(torch.stack(predictions))\n",
        "\n",
        "    HC_mask = (predictions_rounded == 0).squeeze()\n",
        "    mPFC_mask = (predictions_rounded == 1).squeeze()\n",
        "\n",
        "    HC_output = []\n",
        "    for feature in all_inputs[HC_mask]:\n",
        "      HC_output.append(hc.forward(feature))\n",
        "    mPFC_output = []\n",
        "    for feature in all_inputs[mPFC_mask]:\n",
        "      encoded, _ = mpfc.encoder_forward(feature)\n",
        "      mPFC_output.append(mpfc.classify(encoded))\n",
        "    print(HC_output)\n",
        "    print(mPFC_output)\n",
        "    HC_output = torch.stack(HC_output)\n",
        "    mPFC_output = torch.stack(mPFC_output)\n",
        "    combined_output = torch.zeros(all_inputs.size(0), 1, device=all_inputs.device)  # Ensure combined_output has the correct shape\n",
        "\n",
        "    if HC_mask.sum() > 0:  # Ensure there are samples for HC\n",
        "        combined_output[HC_mask] = HC_output.unsqueeze(1) if HC_output.dim() == 1 else HC_output\n",
        "\n",
        "    if mPFC_mask.sum() > 0:  # Ensure there are samples for mPFC\n",
        "        combined_output[mPFC_mask] = mPFC_output.unsqueeze(1) if mPFC_output.dim() == 1 else mPFC_output\n",
        "\n",
        "    return combined_output\n",
        "\n",
        "  def calc_accuracy(self, dataset):\n",
        "    total_correct = 0\n",
        "    total_samples = len(dataset)  # Number of samples in the dataset\n",
        "\n",
        "    with torch.no_grad():\n",
        "        predictions = self.eval(dataset)\n",
        "        predictions = torch.argmax(predictions, dim=1)\n",
        "\n",
        "        correct = (predictions == dataset.labels).sum().item()\n",
        "        total_correct += correct\n",
        "\n",
        "    return (total_correct / total_samples) * 100  # Return accuracy as a percentage\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19jH5R1KWDNV"
      },
      "outputs": [],
      "source": [
        "dmsm = DMSM()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "anAqwCnWzy8w",
        "outputId": "4568c825-65f0-48a6-e2cf-d7fc335ad992"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Loss: 599495843.712, Classification Loss: 3.2188605012893676, Reconstruction Loss: 599495843.712\n",
            "Accuracy: 1.392%\n",
            "Total Loss: 343285191.936, Classification Loss: 2.5943337612152098, Reconstruction Loss: 343285191.936\n",
            "Accuracy: 27.928%\n",
            "Total Loss: 265249406.208, Classification Loss: 2.411891875267029, Reconstruction Loss: 265249406.208\n",
            "Accuracy: 34.8%\n",
            "Total Loss: 228760524.16, Classification Loss: 2.3094126105308534, Reconstruction Loss: 228760524.16\n",
            "Accuracy: 38.2%\n",
            "Total Loss: 205743612.928, Classification Loss: 2.2424271688461306, Reconstruction Loss: 205743612.928\n",
            "Accuracy: 40.412%\n",
            "Total Loss: 191312485.888, Classification Loss: 2.191182502746582, Reconstruction Loss: 191312485.888\n",
            "Accuracy: 42.48%\n",
            "Total Loss: 180417147.136, Classification Loss: 2.152118706703186, Reconstruction Loss: 180417147.136\n",
            "Accuracy: 43.34%\n",
            "Total Loss: 171946500.224, Classification Loss: 2.117611569881439, Reconstruction Loss: 171946500.224\n",
            "Accuracy: 43.5%\n",
            "Total Loss: 166214588.736, Classification Loss: 2.098514630317688, Reconstruction Loss: 166214588.736\n",
            "Accuracy: 44.536%\n",
            "Total Loss: 161017297.152, Classification Loss: 2.0772475728988646, Reconstruction Loss: 161017297.152\n",
            "Accuracy: 44.94%\n",
            "Total Loss: 156592826.496, Classification Loss: 2.0537160000801085, Reconstruction Loss: 156592826.496\n",
            "Accuracy: 45.86%\n",
            "Total Loss: 152877905.632, Classification Loss: 2.03605472612381, Reconstruction Loss: 152877905.632\n",
            "Accuracy: 45.976%\n",
            "Total Loss: 149840503.552, Classification Loss: 2.018911759376526, Reconstruction Loss: 149840503.552\n",
            "Accuracy: 46.092%\n",
            "Total Loss: 146889840.864, Classification Loss: 2.0032123889923095, Reconstruction Loss: 146889840.864\n",
            "Accuracy: 47.012%\n",
            "Total Loss: 144704560.672, Classification Loss: 1.9872313776016235, Reconstruction Loss: 144704560.672\n",
            "Accuracy: 47.3%\n",
            "Total Loss: 143001216.448, Classification Loss: 1.9813752641677858, Reconstruction Loss: 143001216.448\n",
            "Accuracy: 47.596%\n",
            "Total Loss: 140793257.44, Classification Loss: 1.967419575214386, Reconstruction Loss: 140793257.44\n",
            "Accuracy: 47.524%\n",
            "Total Loss: 139511183.776, Classification Loss: 1.9564282636642456, Reconstruction Loss: 139511183.776\n",
            "Accuracy: 48.344%\n",
            "Total Loss: 137903404.48, Classification Loss: 1.952368399143219, Reconstruction Loss: 137903404.48\n",
            "Accuracy: 48.54%\n",
            "Total Loss: 136338733.28, Classification Loss: 1.9397640476226807, Reconstruction Loss: 136338733.28\n",
            "Accuracy: 48.484%\n"
          ]
        }
      ],
      "source": [
        "# instantiate and train mPFC on base knowledge\n",
        "\n",
        "dmsm.base_knowledge()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQCWsiEG28hv"
      },
      "outputs": [],
      "source": [
        "mpfc = mPFC()\n",
        "mpfc.generate_statistics(sorted_feature_vectors[:half], labels[:half])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkB431Xq8-e6"
      },
      "outputs": [],
      "source": [
        "# test accuracy\n",
        "\n",
        "accuracy = dmsm.mpfc.calculate_accuracy(base_dataloader)\n",
        "print(f\"Accuracy: {accuracy}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eQzaOQtIviE"
      },
      "source": [
        "# Incremental Class Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rskHa1ax6YZZ"
      },
      "outputs": [],
      "source": [
        "# DMSM Performance\n",
        "\n",
        "dmsm = DMSM()\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "CIFAR-100:\n",
        "50000 items\n",
        "100 classes\n",
        "500 items/class\n",
        "\"\"\"\n",
        "\n",
        "classes_left = 50\n",
        "index = half\n",
        "\n",
        "accuracy_history = []\n",
        "\n",
        "for i in range(classes_left):\n",
        "    end_index = min(index + 500, len(sorted_feature_vectors))\n",
        "\n",
        "    next_dataset = FeatureDataset(sorted_feature_vectors[index:end_index], sorted_labels[index:end_index])\n",
        "\n",
        "    if i % sleep_frequency == sleep_frequency - 1:\n",
        "        dmsm.sleep()\n",
        "    else:\n",
        "      dmsm.training_session(dataset = next_dataset, BLA_epochs = BLA_Epochs)\n",
        "\n",
        "    classes_sofar = FeatureDataset(sorted_feature_vectors[:end_index], sorted_labels[:end_index])\n",
        "    accuracy_history.append(dmsm.calc_accuracy(classes_sofar))\n",
        "    index = end_index"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Pxb1oT_wLvLv",
        "rdVa6JvuLHcT",
        "3GPXUTBkygJd",
        "lfYC56dhLO8u",
        "EKg46QH1Lefr"
      ],
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}