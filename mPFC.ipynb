{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOdvPG1R5z1Y7YkL6Do+Nvw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SquirrelLover/FearNet-Implementation/blob/main/mPFC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torch.functional as F\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "NAa1Nl-k21SB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Dropout = 0.25\n",
        "Learning_Rate = 2e-3"
      ],
      "metadata": {
        "id": "0yTRBfMI1VgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUxN0nB320I6"
      },
      "outputs": [],
      "source": [
        "# define mPFC (long term)\n",
        "\n",
        "class mPFC(nn.Module):\n",
        "  def __init__(self, input_dim=3072, autoencoder_hidden_dims = np.array([256]), classifier_dims = np.array([961, 525, 289, 100]), lambda_values=None, learning_rate=Learning_Rate):\n",
        "    super(mPFC, self).__init__()\n",
        "    # encoder\n",
        "    encoder_layers = []\n",
        "    current_dim = input_dim\n",
        "    for hidden_dim in autoencoder_hidden_dims:\n",
        "      encoder_layers.append(nn.Linear(current_dim, hidden_dim))\n",
        "      encoder_layers.append(nn.ELU())\n",
        "      current_dim = hidden_dim\n",
        "    self.encoder = nn.Sequential(*encoder_layers)\n",
        "\n",
        "    # decoder\n",
        "    decoder_layers = []\n",
        "    hidden_dims_reversed = list(autoencoder_hidden_dims[::-1])\n",
        "    for hidden_dim in hidden_dims_reversed:\n",
        "      decoder_layers.append(nn.Linear(current_dim, hidden_dim))\n",
        "      decoder_layers.append(nn.ELU())\n",
        "      current_dim = hidden_dim\n",
        "    decoder_layers.append(nn.Linear(current_dim, input_dim))\n",
        "    decoder_layers.append(nn.ELU())\n",
        "    self.decoder = nn.Sequential(*decoder_layers)\n",
        "\n",
        "    #classifier\n",
        "    classifier_layers= []\n",
        "    if len(classifier_dims)!=1:\n",
        "      classifier_layers.append(nn.Linear(current_dim, classifier_dims[0]))\n",
        "      classifier_layers.append(nn.ELU())\n",
        "\n",
        "      for i in range(1, len(classifier_dims)-1):\n",
        "        hidden_dim = classifier_dims[i]\n",
        "        classifier_layers.append(nn.Linear(current_dim, hidden_dim))\n",
        "        classifier_layers.append(nn.ELU())\n",
        "        classifier_layers.append(nn.Dropout(p=Dropout))\n",
        "        current_dim = hidden_dim\n",
        "\n",
        "    classifier_layers.append(nn.Linear(current_dim, classifier_dims[len(classifier_dims)-1]))\n",
        "\n",
        "    self.classifier = nn.Sequential(*classifier_layers)\n",
        "\n",
        "    # lambda\n",
        "    self.lambda_values = torch.tensor(lambda_values if lambda_values else [1.0] * len(autoencoder_hidden_dims), dtype=torch.float32)\n",
        "\n",
        "    # optimizer\n",
        "    self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
        "\n",
        "  def encoder_forward(self, x):\n",
        "    encoder_intermediates = [x]\n",
        "    for layer in self.encoder:\n",
        "      x = layer(x)\n",
        "      encoder_intermediates.append(x)\n",
        "    encoded = encoder_intermediates[-1]\n",
        "    return encoded, encoder_intermediates\n",
        "\n",
        "  def decoder_forward(self, x):\n",
        "    decoder_intermediates = [x]\n",
        "    for layer in self.decoder:\n",
        "      x = layer(x)\n",
        "      decoder_intermediates.append(x)\n",
        "    pseudo_img = decoder_intermediates[-1]\n",
        "    return pseudo_img, list(decoder_intermediates[::-1])\n",
        "\n",
        "  def classify(self, x):\n",
        "    class_logits = self.classifier(x)\n",
        "    return class_logits\n",
        "\n",
        "  def compute_loss(self, class_logits, targets, encoder_intermediates, decoder_intermediates):\n",
        "    # classification loss\n",
        "    classification_loss = nn.CrossEntropyLoss()(class_logits, targets)\n",
        "\n",
        "    # reconstruction loss with lambda weighting\n",
        "    reconstruction_loss = 0\n",
        "    for i in range(len(self.lambda_values)):\n",
        "      encoder_hidden = encoder_intermediates[i]\n",
        "      decoder_hidden = decoder_intermediates[i]\n",
        "      diff = encoder_hidden - decoder_hidden\n",
        "      squared_diff = diff.pow(2)\n",
        "      layer_loss = squared_diff.sum()\n",
        "      reconstruction_loss += self.lambda_values[i] * layer_loss\n",
        "\n",
        "    # total loss\n",
        "    total_loss = classification_loss + reconstruction_loss\n",
        "\n",
        "    return classification_loss, reconstruction_loss, total_loss\n",
        "\n",
        "  def training_step(self, data_loader, device):\n",
        "    self.train()\n",
        "\n",
        "    total_classification_loss = 0\n",
        "    total_reconstruction_loss = 0\n",
        "    total_total_loss = 0\n",
        "\n",
        "    for x, targets in data_loader:\n",
        "      x, targets = x.to(device), targets.to(device)\n",
        "\n",
        "      # forward pass\n",
        "      encoded, encoder_intermediates = self.encoder_forward(x)\n",
        "      pseudo_img, decoder_intermediates = self.decoder_forward(encoded)\n",
        "      class_logits = self.classify(encoded)\n",
        "\n",
        "      # compute losses\n",
        "      classification_loss, reconstruction_loss, total_loss = self.compute_loss(\n",
        "        class_logits, targets, encoder_intermediates, decoder_intermediates\n",
        "      )\n",
        "\n",
        "      # zero gradients\n",
        "      self.optimizer.zero_grad()\n",
        "      for param in self.decoder.parameters():\n",
        "        param.grad = None\n",
        "      for param in self.encoder.parameters():\n",
        "        param.grad = None\n",
        "\n",
        "      # backward pass\n",
        "      classification_loss.backward(retain_graph=True)\n",
        "      classifier_grads = {name: param.grad.clone() for name, param in self.classifier.named_parameters()}\n",
        "      reconstruction_loss.backward(retain_graph=True)\n",
        "      decoder_grads = {name: param.grad.clone() for name, param in self.decoder.named_parameters()}\n",
        "      total_loss.backward()\n",
        "      for name, param in self.encoder.named_parameters():\n",
        "        if param.grad is not None:\n",
        "          param.grad.data = param.grad.data\n",
        "\n",
        "      # optimizer\n",
        "      encoder_optimizer = optim.Adam(self.encoder.parameters(), lr=self.optimizer.defaults['lr'])\n",
        "      encoder_optimizer.step()\n",
        "      classifier_optimizer = optim.Adam(self.classifier.parameters(), lr=self.optimizer.defaults['lr'])\n",
        "      classifier_optimizer.step()\n",
        "      decoder_optimizer = optim.Adam(self.decoder.parameters(), lr=self.optimizer.defaults['lr'])\n",
        "      decoder_optimizer.step()\n",
        "\n",
        "      # update parameters\n",
        "      for name, param in self.classifier.named_parameters():\n",
        "        if param.grad is not None:\n",
        "          param.grad.data = classifier_grads[name].data\n",
        "      for name, param in self.decoder.named_parameters():\n",
        "        if param.grad is not None:\n",
        "          param.grad.data = decoder_grads[name].data\n",
        "\n",
        "      # add losses to total\n",
        "      total_classification_loss += classification_loss.item()\n",
        "      total_reconstruction_loss += reconstruction_loss.item()\n",
        "      total_total_loss += total_loss.item()\n",
        "\n",
        "    # average loss\n",
        "    average_classification_loss = total_classification_loss / len(data_loader)\n",
        "    average_reconstruction_loss = total_reconstruction_loss / len(data_loader)\n",
        "    average_total_loss = total_total_loss / len(data_loader)\n",
        "\n",
        "    return average_classification_loss, average_reconstruction_loss, average_total_loss\n",
        "\n",
        "  def generate_statistics(self, list_feature_vectors, device):\n",
        "    self.eval()\n",
        "\n",
        "    latent_rep = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for x, targets in list_feature_vectors:\n",
        "        x, targets = x.to(device), targets.to(device)\n",
        "\n",
        "        # pass through encoder\n",
        "        mPFC_out, _ = self.mPFC.encoder_forward(x)\n",
        "        latent_rep.append(mPFC_out.cpu())\n",
        "\n",
        "    # stack\n",
        "    latent_rep = torch.cat(latent_rep, dim=0)\n",
        "\n",
        "    # ux\n",
        "    ux_mPFC = latent_rep.mean(dim=0)\n",
        "\n",
        "    # covariance matrix\n",
        "    centered_mPFC_features = latent_rep - ux_mPFC\n",
        "    covariance_matrix_mPFC = torch.matmul(centered_mPFC_features.t(), centered_mPFC_features) / (latent_rep.size(0) - 1)\n",
        "\n",
        "    return ux_mPFC, covariance_matrix_mPFC\n",
        "\n",
        "  def pseudoimg_from_statistics(self, u, covar, count):\n",
        "    self.eval()\n",
        "\n",
        "    # sampling from a multivariate normal distribution\n",
        "    distribution = torch.distributions.MultivariateNormal(u, covar)\n",
        "    sampled_vectors = distribution.sample((count,)).to(device)\n",
        "\n",
        "    # pass through decoder\n",
        "    pseudo_images = []\n",
        "    with torch.no_grad():\n",
        "      for latent_vector in sampled_vectors:\n",
        "        pseudo_img, _ = self.decoder_forward(latent_vector)\n",
        "        pseudo_images.append(pseudo_img.cpu())\n",
        "\n",
        "    # stack\n",
        "    pseudo_images = torch.stack(pseudo_images, dim=0)\n",
        "\n",
        "    return pseudo_images"
      ]
    }
  ]
}