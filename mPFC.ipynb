{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMFitsU84UpzLBC2O5bmzkL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SquirrelLover/FearNet-Implementation/blob/main/mPFC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.functional as F\n",
        "from torchsummary import summary\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset, random_split, TensorDataset\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet50"
      ],
      "metadata": {
        "id": "NAa1Nl-k21SB"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Mini_batch = 450\n",
        "Dropout = 0.25\n",
        "Learning_Rate = 2e-3"
      ],
      "metadata": {
        "id": "0yTRBfMI1VgO"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset (CIFAR-100)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "train_data = torchvision.datasets.CIFAR100(root='./data', train=True, transform = transform, download = True)\n",
        "test_data = torchvision.datasets.CIFAR100(root='./data', train=False, transform = transform, download = True)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size = Mini_batch, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size = Mini_batch, shuffle=False)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# view a couple of sample images to make sure they are loaded\n",
        "\n",
        "print(\"Train Loader Images:\")\n",
        "images, labels = next(iter(train_loader))\n",
        "images = images.cpu().detach().numpy()\n",
        "plt.figure(figsize=(16, 4))\n",
        "for i in range(4):\n",
        "  plt.subplot(1, 4, i+1)\n",
        "  plt.imshow(np.transpose(images[i], (1, 2, 0)))\n",
        "  plt.axis('off')\n",
        "  plt.title(f\"Image of class {labels[i].item()}\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "gjJ6jJsagCvO",
        "outputId": "783f43dc-1be8-4d4c-fc49-905a3cd36685"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Train Loader Images:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x400 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Resnet processing\n",
        "\n",
        "resnet = resnet50(pretrained=True)\n",
        "resnet = resnet.to(device)\n",
        "resnet.eval()\n",
        "\n",
        "resnet_feature_extractor = nn.Sequential(*list(resnet.children())[:-1])\n",
        "\n",
        "num_images = len(train_data)\n",
        "feature_vectors = np.zeros((num_images, 2048))\n",
        "labels = np.zeros(num_images)\n",
        "\n",
        "class CIFAR100FeatureDataset(Dataset):\n",
        "    def __init__(self, dataset):\n",
        "        self.dataset = dataset\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image, label = self.dataset[idx]\n",
        "        return image, label\n",
        "\n",
        "feature_dataset = CIFAR100FeatureDataset(train_data)\n",
        "feature_loader = DataLoader(feature_dataset, batch_size=Mini_batch, shuffle=False)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, (images, labels_batch) in enumerate(feature_loader):\n",
        "        images = images.to(device)\n",
        "        features_batch = resnet_feature_extractor(images).squeeze().cpu().numpy()\n",
        "        start_index = i * Mini_batch\n",
        "        end_index = start_index + features_batch.shape[0]\n",
        "        feature_vectors[start_index:end_index] = features_batch\n",
        "        labels[start_index:end_index] = labels_batch.numpy()\n",
        "\n",
        "feature_vectors = torch.tensor(feature_vectors, dtype=torch.float32)\n",
        "labels = torch.tensor(labels).long()\n",
        "\n",
        "print(\"Features shape:\", feature_vectors.shape)\n",
        "print(\"Labels shape:\", labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvJX8qO26DEb",
        "outputId": "ece31ac0-2980-4c0e-8d2c-3a3efed34422"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features shape: torch.Size([50000, 2048])\n",
            "Labels shape: torch.Size([50000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "FUxN0nB320I6"
      },
      "outputs": [],
      "source": [
        "# define mPFC (long term)\n",
        "\n",
        "class mPFC(nn.Module):\n",
        "  def __init__(self, input_dim=2048, autoencoder_hidden_dims = np.array([1024, 512]), classifier_dims = np.array([1024, 100]), lambda_values=[1e4, 1.0, 0.1], learning_rate=2e-3):\n",
        "    super(mPFC, self).__init__()\n",
        "    # encoder\n",
        "    encoder_layers = []\n",
        "    current_dim = input_dim\n",
        "    encoder_layers.append(nn.ELU())\n",
        "    for hidden_dim in autoencoder_hidden_dims:\n",
        "      encoder_layers.append(nn.Linear(current_dim, hidden_dim))\n",
        "      encoder_layers.append(nn.ELU())\n",
        "      current_dim = hidden_dim\n",
        "    self.encoder = nn.Sequential(*encoder_layers)\n",
        "\n",
        "    # decoder\n",
        "    decoder_layers = []\n",
        "    hidden_dims_reversed = list(autoencoder_hidden_dims[::-1])\n",
        "    for hidden_dim in hidden_dims_reversed:\n",
        "      decoder_layers.append(nn.Linear(current_dim, hidden_dim))\n",
        "      decoder_layers.append(nn.ELU())\n",
        "      current_dim = hidden_dim\n",
        "    decoder_layers.append(nn.Linear(current_dim, input_dim))\n",
        "    decoder_layers.append(nn.ELU())\n",
        "    self.decoder = nn.Sequential(*decoder_layers)\n",
        "\n",
        "    #classifier\n",
        "    current_dim = autoencoder_hidden_dims[-1]\n",
        "    classifier_layers= []\n",
        "\n",
        "    if len(classifier_dims) != 1:\n",
        "      classifier_layers.append(nn.Linear(current_dim, classifier_dims[0]))\n",
        "      classifier_layers.append(nn.ELU())\n",
        "      classifier_layers.append(nn.Dropout(p=Dropout))\n",
        "      current_dim = classifier_dims[0]\n",
        "\n",
        "      for i in range(1, len(classifier_dims)-1):\n",
        "        hidden_dim = classifier_dims[i]\n",
        "        classifier_layers.append(nn.Linear(current_dim, hidden_dim))\n",
        "        classifier_layers.append(nn.ELU())\n",
        "        classifier_layers.append(nn.Dropout(p=Dropout))\n",
        "        current_dim = hidden_dim\n",
        "\n",
        "    classifier_layers.append(nn.Linear(current_dim, classifier_dims[len(classifier_dims)-1]))\n",
        "\n",
        "    self.classifier = nn.Sequential(*classifier_layers)\n",
        "\n",
        "    # lambda\n",
        "    self.lambda_values = torch.tensor(lambda_values if lambda_values else [1.0] * len(autoencoder_hidden_dims), dtype=torch.float32)\n",
        "\n",
        "    # optimizer\n",
        "    self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
        "\n",
        "  def encoder_forward(self, x):\n",
        "    encoder_intermediates = [x]\n",
        "    for layer in self.encoder:\n",
        "      x = layer(x)\n",
        "      encoder_intermediates.append(x)\n",
        "    encoded = encoder_intermediates[-1]\n",
        "    return encoded, encoder_intermediates\n",
        "\n",
        "  def decoder_forward(self, x):\n",
        "    decoder_intermediates = [x]\n",
        "    for layer in self.decoder:\n",
        "      x = layer(x)\n",
        "      decoder_intermediates.append(x)\n",
        "    pseudo_img = decoder_intermediates[-1]\n",
        "    return pseudo_img, list(decoder_intermediates[::-1])\n",
        "\n",
        "  def classify(self, x):\n",
        "    class_logits = self.classifier(x)\n",
        "    return class_logits\n",
        "\n",
        "  def compute_loss(self, class_logits, targets, encoder_intermediates, decoder_intermediates):\n",
        "    # classification loss\n",
        "    classification_loss = nn.CrossEntropyLoss()(class_logits, targets)\n",
        "\n",
        "    # reconstruction loss with lambda weighting\n",
        "    reconstruction_loss = 0\n",
        "    for i in range(len(self.lambda_values)):\n",
        "      encoder_hidden = encoder_intermediates[i]\n",
        "      decoder_hidden = decoder_intermediates[i]\n",
        "      diff = encoder_hidden - decoder_hidden\n",
        "      squared_diff = diff.pow(2)\n",
        "      layer_loss = squared_diff.sum()\n",
        "      reconstruction_loss += self.lambda_values[i] * layer_loss\n",
        "\n",
        "    # total loss\n",
        "    total_loss = classification_loss + reconstruction_loss\n",
        "\n",
        "    return classification_loss, reconstruction_loss, total_loss\n",
        "\n",
        "  def training_step(self, data_loader, device):\n",
        "    self.train()\n",
        "\n",
        "    total_classification_loss = 0\n",
        "    total_reconstruction_loss = 0\n",
        "    total_total_loss = 0\n",
        "\n",
        "    for x, targets in data_loader:\n",
        "      x, targets = x.to(device), targets.to(device)\n",
        "\n",
        "      # forward pass\n",
        "      encoded, encoder_intermediates = self.encoder_forward(x)\n",
        "      pseudo_img, decoder_intermediates = self.decoder_forward(encoded)\n",
        "      class_logits = self.classify(encoded)\n",
        "      # compute losses\n",
        "      classification_loss, reconstruction_loss, total_loss = self.compute_loss(\n",
        "        class_logits, targets, encoder_intermediates, decoder_intermediates\n",
        "      )\n",
        "\n",
        "      # zero gradients\n",
        "      self.optimizer.zero_grad()\n",
        "      for param in self.decoder.parameters():\n",
        "        param.grad = None\n",
        "      for param in self.encoder.parameters():\n",
        "        param.grad = None\n",
        "\n",
        "      # backward pass\n",
        "      classification_loss.backward(retain_graph=True)\n",
        "      classifier_grads = {name: param.grad.clone() for name, param in self.classifier.named_parameters()}\n",
        "      reconstruction_loss.backward(retain_graph=True)\n",
        "      decoder_grads = {name: param.grad.clone() for name, param in self.decoder.named_parameters()}\n",
        "      total_loss.backward()\n",
        "      for name, param in self.encoder.named_parameters():\n",
        "        if param.grad is not None:\n",
        "          param.grad.data = param.grad.data\n",
        "\n",
        "      # optimizer\n",
        "      encoder_optimizer = optim.Adam(self.encoder.parameters(), lr=self.optimizer.defaults['lr'])\n",
        "      encoder_optimizer.step()\n",
        "      classifier_optimizer = optim.Adam(self.classifier.parameters(), lr=self.optimizer.defaults['lr'])\n",
        "      classifier_optimizer.step()\n",
        "      decoder_optimizer = optim.Adam(self.decoder.parameters(), lr=self.optimizer.defaults['lr'])\n",
        "      decoder_optimizer.step()\n",
        "\n",
        "      # update parameters\n",
        "      for name, param in self.classifier.named_parameters():\n",
        "        if param.grad is not None:\n",
        "          param.grad.data = classifier_grads[name].data\n",
        "      for name, param in self.decoder.named_parameters():\n",
        "        if param.grad is not None:\n",
        "          param.grad.data = decoder_grads[name].data\n",
        "\n",
        "      # add losses to total\n",
        "      total_classification_loss += classification_loss.item()\n",
        "      total_reconstruction_loss += reconstruction_loss.item()\n",
        "      total_total_loss += total_loss.item()\n",
        "\n",
        "    # average loss\n",
        "    average_classification_loss = total_classification_loss / len(data_loader)\n",
        "    average_reconstruction_loss = total_reconstruction_loss / len(data_loader)\n",
        "    average_total_loss = total_total_loss / len(data_loader)\n",
        "\n",
        "    return average_classification_loss, average_reconstruction_loss, average_total_loss\n",
        "\n",
        "  def generate_statistics(self, list_feature_vectors, device):\n",
        "    self.eval()\n",
        "\n",
        "    latent_rep = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for x, targets in list_feature_vectors:\n",
        "        x, targets = x.to(device), targets.to(device)\n",
        "\n",
        "        # pass through encoder\n",
        "        mPFC_out, _ = self.encoder_forward(x)\n",
        "        latent_rep.append(mPFC_out.cpu())\n",
        "\n",
        "    # stack\n",
        "    latent_rep = torch.cat(latent_rep, dim=0)\n",
        "\n",
        "    # ux\n",
        "    ux_mPFC = latent_rep.mean(dim=0)\n",
        "\n",
        "    # covariance matrix\n",
        "    centered_mPFC_features = latent_rep - ux_mPFC\n",
        "    covariance_matrix_mPFC = torch.matmul(centered_mPFC_features.t(), centered_mPFC_features) / (latent_rep.size(0) - 1)\n",
        "\n",
        "    return ux_mPFC, covariance_matrix_mPFC\n",
        "\n",
        "  def pseudoimg_from_statistics(self, u, covar, count):\n",
        "    self.eval()\n",
        "\n",
        "    # sampling from a multivariate normal distribution\n",
        "    distribution = torch.distributions.MultivariateNormal(u, covar)\n",
        "    sampled_vectors = distribution.sample((count,)).to(device)\n",
        "\n",
        "    # pass through decoder\n",
        "    pseudo_images = []\n",
        "    with torch.no_grad():\n",
        "      for latent_vector in sampled_vectors:\n",
        "        pseudo_img, _ = self.decoder_forward(latent_vector)\n",
        "        pseudo_images.append(pseudo_img.cpu())\n",
        "\n",
        "    # stack\n",
        "    pseudo_images = torch.stack(pseudo_images, dim=0)\n",
        "\n",
        "    return pseudo_images\n",
        "\n",
        "  def calculate_accuracy(self, data_loader, device):\n",
        "    self.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for x, targets in data_loader:\n",
        "        x, targets = x.to(device), targets.to(device)\n",
        "        encoded, _ = self.encoder_forward(x)\n",
        "        class_logits = self.classify(encoded)\n",
        "        _, predicted = torch.max(class_logits.data, 1)\n",
        "        total += targets.size(0)\n",
        "        correct += (predicted == targets).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = mPFC()\n",
        "model = model.to(device)\n",
        "\n",
        "#print(summary(model.encoder, input_size=(3072,)))\n",
        "#print(summary(model.decoder, input_size=(256,)))\n",
        "\n",
        "class FeatureDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = features\n",
        "        self.labels = labels.long()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        feature = self.features[idx]\n",
        "        label = self.labels[idx]\n",
        "        return feature, label\n",
        "\n",
        "dataset = FeatureDataset(feature_vectors, labels)\n",
        "data_loader = DataLoader(dataset, batch_size=Mini_batch, shuffle=True)\n",
        "\n",
        "for epoch in range(100):\n",
        "    data_loader = DataLoader(dataset, batch_size=Mini_batch, shuffle=True)\n",
        "\n",
        "    avg_classification_loss, avg_reconstruction_loss, avg_total_loss = model.training_step(data_loader, device)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Total Loss: {avg_total_loss}, Classification Loss: {avg_classification_loss}, Reconstruction Loss: {avg_reconstruction_loss}\")\n",
        "    #for param_group in model.optimizer.param_groups:\n",
        "    #    print(\"Learning rate:\", param_group['lr'])\n",
        "    #for name, param in model.named_parameters():\n",
        "    #    if param.grad is not None:\n",
        "    #        print(f\"{name} gradient norm: {param.grad.norm().item()}\")\n",
        "\n",
        "    accuracy = model.calculate_accuracy(data_loader, device)\n",
        "    print(f\"Epoch {epoch+1}, Accuracy: {accuracy}%\")"
      ],
      "metadata": {
        "id": "BzxGXR78gedJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}